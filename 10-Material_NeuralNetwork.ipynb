{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Overview\n",
        "\n",
        "We will use pytorch for training our neural networks. First, we will look at the overall pipeline to train and validate the model. For this, we will use ML models from already available python pacakges like ``dgl`` and ``deepchem``.\n",
        "\n",
        "\n",
        "The process of training and validating model is below --\n",
        "\n",
        "1. Clean up dataset\n",
        "2. Featurize the data\n",
        "3. Split the dataset\n",
        "4. Create ``DataLoader`` for the dataset splits\n",
        "5. Create the ML model, define loss function and optimizer\n",
        "6. ``for`` loop for epochs\n",
        "    1. ``for`` loop for training batches\n",
        "        1. Do a forward pass\n",
        "        2. Compute the loss\n",
        "        3. Do backpropogation\n",
        "    2. ``for`` loop for validation batches\n",
        "        1. Do a forward pass\n",
        "        2. Compute the loss\n",
        "    "
      ],
      "metadata": {
        "id": "lOVwv8YkB7Pd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing the packages"
      ],
      "metadata": {
        "id": "5658_JEJnxfS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HC4Yn8cLAaC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1ff6be-9e3b-499c-ef9a-f98db545d52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepchem\n",
            "  Downloading deepchem-2.7.1-py3-none-any.whl (693 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.2/693.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.2)\n",
            "Collecting scipy<1.9 (from deepchem)\n",
            "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit (from deepchem)\n",
            "  Downloading rdkit-2023.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2023.3.post1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (9.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->deepchem) (1.16.0)\n",
            "Installing collected packages: scipy, rdkit, deepchem\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.3\n",
            "    Uninstalling scipy-1.11.3:\n",
            "      Successfully uninstalled scipy-1.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "jax 0.4.20 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "jaxlib 0.4.20+cuda11.cudnn86 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deepchem-2.7.1 rdkit-2023.9.1 scipy-1.8.1\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.1.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.8.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.2\n",
            "Collecting dgllife\n",
            "  Downloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgllife) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.8.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgllife) (3.2.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from dgllife) (0.2.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.16.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2023.3.post1)\n",
            "Installing collected packages: dgllife\n",
            "Successfully installed dgllife-0.3.2\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Collecting fast_ml\n",
            "  Downloading fast_ml-3.68-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fast_ml\n",
            "Successfully installed fast_ml-3.68\n"
          ]
        }
      ],
      "source": [
        "# install deepchem, dgl, rdkit and fast-ml\n",
        "! pip install deepchem\n",
        "! pip install dgl\n",
        "! pip install dgllife\n",
        "! pip install rdkit\n",
        "! pip install fast_ml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset operations\n",
        "\n",
        "We will fetch the QM9 dataset and use HOMO-LUMO gap as the target for prediction."
      ],
      "metadata": {
        "id": "136hy3mDHYFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# load the dataframe as CSV from URL.\n",
        "df = pd.read_csv(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\")\n",
        "\n",
        "# create the dataset with smiles and gap\n",
        "dataset = df[[\"smiles\",\"gap\"]]"
      ],
      "metadata": {
        "id": "_9KYkMU1FJ3r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For featurizing the SMILES, we will use ``CircularFingerprint`` from deepchem."
      ],
      "metadata": {
        "id": "rs3sQHgOoh1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import depechem and rdkit\n",
        "import deepchem as dc\n",
        "from rdkit import Chem\n",
        "\n",
        "# create the featurizer object\n",
        "featurizer = dc.feat.CircularFingerprint(radius=2, size=100)\n",
        "\n",
        "# apply the featurizer to dataset\n",
        "dataset[\"fp\"] = dataset[\"smiles\"].apply(featurizer.featurize)\n",
        "\n",
        "# the fp is an array; we will convert it to a list as required for model input\n",
        "dataset[\"fp\"] = dataset[\"fp\"].apply(lambda x: list(x[0]))\n",
        "\n",
        "# just use the fp and gap part of the dataset\n",
        "dataset = dataset[[\"fp\",\"gap\"]]"
      ],
      "metadata": {
        "id": "M05vMWS6FT0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2721a157-c607-4c10-8093-081b70bc1e9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.10/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n",
            "<ipython-input-3-a48f0833e7a3>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[\"fp\"] = dataset[\"smiles\"].apply(featurizer.featurize)\n",
            "<ipython-input-3-a48f0833e7a3>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[\"fp\"] = dataset[\"fp\"].apply(lambda x: list(x[0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we use random splitting with Fast-ML. Other splitters could also be used."
      ],
      "metadata": {
        "id": "eOhc1WzunuEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the function to split into train-valid-test\n",
        "from fast_ml.model_development import train_valid_test_split\n",
        "\n",
        "X_train, y_train, X_valid, y_valid, \\\n",
        "X_test, y_test = train_valid_test_split(dataset, target = \"gap\", train_size=0.8,\n",
        "                                        valid_size=0.1, test_size=0.1)"
      ],
      "metadata": {
        "id": "0Uz09CqxF-2f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the dataset before procceding."
      ],
      "metadata": {
        "id": "wEgPjvkypgp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "id": "BE5KuSqnHOsq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ba99ec75-4bb1-424e-a173-bc8642d8c99a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       fp\n",
              "48879   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...\n",
              "133459  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...\n",
              "77180   [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...\n",
              "87586   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "20037   [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f535339-bf6a-49f3-8db3-9978b250a284\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48879</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133459</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77180</th>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87586</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20037</th>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f535339-bf6a-49f3-8db3-9978b250a284')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f535339-bf6a-49f3-8db3-9978b250a284 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f535339-bf6a-49f3-8db3-9978b250a284');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-286e0699-a2aa-48a0-8d77-94715fc47ade\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-286e0699-a2aa-48a0-8d77-94715fc47ade')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-286e0699-a2aa-48a0-8d77-94715fc47ade button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader\n",
        "\n",
        "The ``DataLoader`` helps in creating batches, shuffling data and feeding the data into to model during training. The dataloader requires the dataset in the form (X,y) where X is the input and y is the target.\n",
        "\n",
        "The dataloader code below does this transformation. The ``collate_data`` function is need for batching the (X,y) entries before feeding the batches into the model."
      ],
      "metadata": {
        "id": "fu7uSLoJKfjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_data(data):\n",
        "  # our data is in the form of list of (X,y)\n",
        "  # the map function thus maps accordingly\n",
        "  X, y = map(list, zip(*data))\n",
        "\n",
        "  # we need to stack the Xs and ys for different entries in the batch\n",
        "  X = torch.stack(X, dim=0)\n",
        "  y = torch.stack(y, dim=0)\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "wNAZGrMuY8yT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataloader\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# create the dataloader for train dataset\n",
        "# dataset should be of form (X,y) according to the collate function\n",
        "# the inputs should also be converted to tensors\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=list(zip(torch.tensor(X_train[\"fp\"].values.tolist(), dtype=torch.float32),\n",
        "                     torch.tensor(y_train.tolist(), dtype=torch.float32))),\n",
        "    batch_size=64, collate_fn=collate_data)"
      ],
      "metadata": {
        "id": "QG1Ie35wJsiE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can look at the first entry of the train_dataloader with -"
      ],
      "metadata": {
        "id": "7b73yfdorVEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader.dataset[0]"
      ],
      "metadata": {
        "id": "1gxYN8NYL8P-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a0e428-5097-4fec-9b94-9236ce8b71b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "         1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
              " tensor(0.2654))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat the same for the valid_dataset and test_dataset"
      ],
      "metadata": {
        "id": "9kv-d9Y0ru8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataloader = DataLoader(\n",
        "    dataset=list(zip(torch.tensor(X_valid[\"fp\"].values.tolist(), dtype=torch.float32),\n",
        "                     torch.tensor(y_valid.tolist(), dtype=torch.float32))),\n",
        "    batch_size=64, collate_fn=collate_data)\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=list(zip(torch.tensor(X_test[\"fp\"].values.tolist(), dtype=torch.float32),\n",
        "                     torch.tensor(y_test.tolist(), dtype=torch.float32))),\n",
        "    batch_size=64, collate_fn=collate_data)"
      ],
      "metadata": {
        "id": "CfmWl76dKpl0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model, loss and optimizer\n",
        "\n",
        "ML models architectures are already available in many python packages including deepchem, dgl-lifesci, chemprop, chemml.\n",
        "\n",
        "Here, we will use a model from dgl-lifesci package to show the process of training a ML model. deepchem has a streamlined process and you cannot see what happens behind the scene. We will look at one such implementation later."
      ],
      "metadata": {
        "id": "-fotYO2ZHhvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import MLP model from dgl-lifesci\n",
        "from dgllife.model.model_zoo.mlp_predictor import MLPPredictor\n",
        "\n",
        "model = MLPPredictor(in_feats=100, hidden_feats=512, n_tasks=1, dropout=0.)\n",
        "model"
      ],
      "metadata": {
        "id": "AhGhxXPdHQR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972d7c51-b0a6-4212-b20f-b1e906d283dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPPredictor(\n",
              "  (predict): Sequential(\n",
              "    (0): Dropout(p=0.0, inplace=False)\n",
              "    (1): Linear(in_features=100, out_features=512, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ``MLPPredictor`` is a simple two layer model with dropout, batchnorm and ReLU activation. This alone may not be a good model, but is inexpensive for training demonstration.\n",
        "\n",
        "Once the model is created, we can set the loss function"
      ],
      "metadata": {
        "id": "uEG7a44fp27c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function for regresssion is usually mean squared error\n",
        "import torch\n",
        "\n",
        "loss_func = torch.nn.MSELoss(reduce=None)"
      ],
      "metadata": {
        "id": "rtzhleqWJHUg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the Adam optimizer for training."
      ],
      "metadata": {
        "id": "HDWEFt02p8X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adam optimier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "KCe6e4l4Jjft"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training and validation\n",
        "\n",
        "We follow the steps in the overview"
      ],
      "metadata": {
        "id": "Ewu1-wIYMPeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "# loop over epochs\n",
        "for epoch in range(epochs):\n",
        "  print(\"\\nStarting Epoch\", epoch+1)\n",
        "\n",
        "  model.train()\n",
        "  # loop over training batches\n",
        "\n",
        "  train_loss = []\n",
        "  for batch in train_dataloader:\n",
        "\n",
        "    # Do a forward pass\n",
        "    feats, target = batch\n",
        "    predictions = model(feats)\n",
        "\n",
        "    # Compute loss and gradient\n",
        "    loss = (loss_func(predictions, target)).mean()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Do back propogation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # save loss to compute average loss\n",
        "    train_loss.append(loss)\n",
        "\n",
        "  print(\"Training loss\", torch.tensor(train_loss).mean().item())\n",
        "\n",
        "\n",
        "  # loop over validation batches\n",
        "  model.eval()\n",
        "  valid_loss = []\n",
        "  with torch.no_grad():\n",
        "    for batch in valid_dataloader:\n",
        "\n",
        "      # Do a forward pass\n",
        "      feats, target = batch\n",
        "      predictions = model(feats)\n",
        "\n",
        "      # Compute loss and gradient\n",
        "      loss = (loss_func(predictions, target)).mean()\n",
        "      valid_loss.append(loss)\n",
        "  print(\"Validation loss \", torch.tensor(valid_loss).mean().item())\n"
      ],
      "metadata": {
        "id": "is7r-fWuKYMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee18089-3f29-4541-f3d6-48bd6004de31"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Epoch 1\n",
            "Training loss 0.007861745543777943\n",
            "Validation loss  0.0023489021696150303\n",
            "\n",
            "Starting Epoch 2\n",
            "Training loss 0.002469493541866541\n",
            "Validation loss  0.0029704011976718903\n",
            "\n",
            "Starting Epoch 3\n",
            "Training loss 0.0026531554758548737\n",
            "Validation loss  0.0025452375411987305\n",
            "\n",
            "Starting Epoch 4\n",
            "Training loss 0.002550845965743065\n",
            "Validation loss  0.0024154025595635176\n",
            "\n",
            "Starting Epoch 5\n",
            "Training loss 0.0023934156633913517\n",
            "Validation loss  0.002320339670404792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the performance\n",
        "\n",
        "We can get a random sample from the test dataset and look at the predicted and true value"
      ],
      "metadata": {
        "id": "GznlVwBCqIKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 159\n",
        "x_sample = X_test[\"fp\"].iloc[idx]\n",
        "y_sample = y_test.iloc[idx]\n",
        "\n",
        "y_sample"
      ],
      "metadata": {
        "id": "VLPTF8QYN-tI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd2318f-bad7-4408-bbb2-5878f3cb41e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2871"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "model(torch.tensor([x_sample], dtype=torch.float32))"
      ],
      "metadata": {
        "id": "_rwTE1NDYW8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b0c08e-0d08-47b9-f63d-306fc5a21704"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2517]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us get prediction over the entire test dataset"
      ],
      "metadata": {
        "id": "pAmzHCFPqMsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values = []\n",
        "true_values = y_test.to_list()\n",
        "\n",
        "model.eval()\n",
        "for sample in X_test[\"fp\"].tolist():\n",
        "   prediction = model(torch.tensor([x_sample], dtype=torch.float32))\n",
        "   predicted_values.append(prediction.item())"
      ],
      "metadata": {
        "id": "YiRQBhA-hHEp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create a scatter plot to look at the correlation"
      ],
      "metadata": {
        "id": "2Dm2_Ztcqa9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(true_values, predicted_values)"
      ],
      "metadata": {
        "id": "_uENBx8EqdpM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "3b74fb07-30fd-4a5e-8119-b469538c6c1a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x797236b5b1c0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we noted before, the model predictions are not good; predicts nearly constant value. We can also arrive at the conclusion from the R<sup>2</sup> score"
      ],
      "metadata": {
        "id": "_lfgLQO2qSMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "print(\"R2 score \", r2_score(true_values, predicted_values))"
      ],
      "metadata": {
        "id": "E_VCh7Qti15_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f7ebc6-df0b-4e81-8b40-5803f1ebd93a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score  -1.3436513860431987e-05\n"
          ]
        }
      ]
    }
  ]
}