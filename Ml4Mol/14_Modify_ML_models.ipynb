{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmirJlr/Molecular-Property-Prediction/blob/master/Ml4Mol/14_Modify_ML_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating custom ML models\n",
        "\n",
        "So far we have used ML models available in the python packages. Here, we will look into the code for the models and see how we can tweek it to make new ML models.\n",
        "\n",
        "We will use the MPNN model from `dgl` and make changes to the model. We will test those models on a subset of the QM9 dataset as before.\n",
        "\n"
      ],
      "metadata": {
        "id": "4vvbsbiaBPpY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing packages and creating the dataloader"
      ],
      "metadata": {
        "id": "W242HZqnCSgW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hnb5DmnnBAui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd2aa7d-8bfe-405b-9270-b918a5caa066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, dgl\n",
            "Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting dgllife\n",
            "  Downloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgllife) (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgllife) (3.2.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from dgllife) (0.2.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.16.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2023.4)\n",
            "Installing collected packages: dgllife\n",
            "Successfully installed dgllife-0.3.2\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.5\n",
            "Collecting fast_ml\n",
            "  Downloading fast_ml-3.68-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fast_ml\n",
            "Successfully installed fast_ml-3.68\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.4.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.2\n"
          ]
        }
      ],
      "source": [
        "# install dgl, rdkit and fast-ml\n",
        "! pip install dgl\n",
        "! pip install dgllife\n",
        "! pip install rdkit\n",
        "! pip install fast_ml\n",
        "! pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# load the dataframe as CSV from URL.\n",
        "df = pd.read_csv(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\")\n",
        "\n",
        "# create the dataset with smiles and gap\n",
        "# we will use a 5% of the dataset to save time\n",
        "dataset = df[[\"smiles\",\"gap\"]].sample(frac=0.05)\n",
        "\n",
        "# import from rdkit and dgl-lifesci\n",
        "from rdkit import Chem\n",
        "from dgllife.utils import CanonicalAtomFeaturizer, CanonicalBondFeaturizer, \\\n",
        "mol_to_bigraph\n",
        "\n",
        "# create the atom and bond featurizer object\n",
        "atom_featurizer = CanonicalAtomFeaturizer(atom_data_field=\"hv\")\n",
        "bond_featurizer = CanonicalBondFeaturizer(bond_data_field=\"he\")\n",
        "\n",
        "# helper function to convert smiles to graph\n",
        "def smiles2graph(smiles):\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "  graph = mol_to_bigraph(mol, node_featurizer=atom_featurizer,\n",
        "                     edge_featurizer=bond_featurizer)\n",
        "  return graph\n",
        "\n",
        "dataset[\"graph\"] = dataset[\"smiles\"].apply(smiles2graph)\n",
        "\n",
        "\n",
        "# import the function to split into train-valid-test\n",
        "from fast_ml.model_development import train_valid_test_split\n",
        "\n",
        "X_train, y_train, X_valid, y_valid, \\\n",
        "X_test, y_test = train_valid_test_split(dataset[[\"graph\",\"gap\"]],\n",
        "                                        target = \"gap\",\n",
        "                                        train_size=0.8,\n",
        "                                        valid_size=0.1,\n",
        "                                        test_size=0.1)\n",
        "\n",
        "# Creating dataloader\n",
        "import dgl\n",
        "\n",
        "def collate_data(data):\n",
        "  # our data is in the form of list of (X,y)\n",
        "  # the map function thus maps accordingly\n",
        "  graphs, y = map(list, zip(*data))\n",
        "\n",
        "  # for creating a batch of graph, we use the batch function\n",
        "  batch_graph = dgl.batch(graphs)\n",
        "\n",
        "  # we need to stack the ys for different entries in the batch\n",
        "  y = torch.stack(y, dim=0)\n",
        "\n",
        "  return batch_graph, y\n",
        "\n",
        "# import dataloader\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# create the dataloader for train dataset\n",
        "# dataset should be of form (X,y) according to the collate function\n",
        "# the ys should also be converted to tensors\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=list(zip(X_train[\"graph\"].values.tolist(),\n",
        "                     torch.tensor(y_train.tolist(), dtype=torch.float32))),\n",
        "    batch_size=64, collate_fn=collate_data)\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset=list(zip(X_valid[\"graph\"].values.tolist(),\n",
        "                     torch.tensor(y_valid.tolist(), dtype=torch.float32))),\n",
        "    batch_size=64, collate_fn=collate_data)\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=list(zip(X_test[\"graph\"].values.tolist(),\n",
        "                     torch.tensor(y_test.tolist(), dtype=torch.float32))),\n",
        "    batch_size=64, collate_fn=collate_data)\n",
        "\n",
        "# loss function for regresssion is usually mean squared error\n",
        "import torch\n",
        "\n",
        "loss_func = torch.nn.MSELoss(reduce=None)"
      ],
      "metadata": {
        "id": "_pIdh3HYCawB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12f87d6-9117-4ec4-e52e-8c3033ba7d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to train and validate the model"
      ],
      "metadata": {
        "id": "OgYfBiefDTE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_train_valid(model, optimizer, loss_func,\n",
        "                    train_dataloader, valid_dataloader):\n",
        "\n",
        "      epochs = 1\n",
        "\n",
        "      # loop over epochs\n",
        "      for epoch in range(epochs):\n",
        "        print(\"\\nStarting Epoch\", epoch+1)\n",
        "\n",
        "        # set the model to train so the parameters can be updated\n",
        "        model.train()\n",
        "        # loop over training batches\n",
        "\n",
        "        train_loss = []\n",
        "        for batch in train_dataloader:\n",
        "\n",
        "          # Do a forward pass\n",
        "          batch_graph, target = batch\n",
        "\n",
        "          # look at the forward function for input\n",
        "          # this model needs graph, node_feats and edge_feats\n",
        "          node_feats = batch_graph.ndata[\"hv\"]\n",
        "          edge_feats = batch_graph.edata[\"he\"]\n",
        "          predictions = model(batch_graph, node_feats, edge_feats)\n",
        "\n",
        "          # Compute loss\n",
        "          loss = (loss_func(predictions, target)).mean()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Do back propogation and update gradient\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # save loss to compute average loss\n",
        "          train_loss.append(loss)\n",
        "\n",
        "        print(\"Training loss\", torch.tensor(train_loss).mean().item())\n",
        "\n",
        "\n",
        "\n",
        "        # set the model to eval so the parameters are not updated\n",
        "        model.eval()\n",
        "        valid_loss = []\n",
        "\n",
        "        # loop over validation batches\n",
        "        with torch.no_grad():\n",
        "          for batch in valid_dataloader:\n",
        "\n",
        "            # Do a forward pass\n",
        "            batch_graph, target = batch\n",
        "            node_feats = batch_graph.ndata[\"hv\"]\n",
        "            edge_feats = batch_graph.edata[\"he\"]\n",
        "            predictions = model(batch_graph, node_feats, edge_feats)\n",
        "\n",
        "            # Compute loss and gradient\n",
        "            loss = (loss_func(predictions, target)).mean()\n",
        "\n",
        "            # save loss to compute average loss\n",
        "            valid_loss.append(loss)\n",
        "\n",
        "        print(\"Validation loss\", torch.tensor(valid_loss).mean().item())\n"
      ],
      "metadata": {
        "id": "KqpMLMQIC4Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the default MPNN model"
      ],
      "metadata": {
        "id": "7l3g-AmSDtHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import MLP model from dgl-lifesci\n",
        "from dgllife.model.model_zoo.mpnn_predictor import MPNNPredictor\n",
        "\n",
        "# the atom feature length is 74 and bond is 12\n",
        "model = MPNNPredictor(node_in_feats = 74,\n",
        "                      edge_in_feats = 12,\n",
        "                      node_out_feats = 64,\n",
        "                      edge_hidden_feats = 128,\n",
        "                      n_tasks = 1,\n",
        "                      num_step_message_passing = 6,\n",
        "                      num_step_set2set = 6,\n",
        "                      num_layer_set2set = 3)\n",
        "\n",
        "# adam optimier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "run_train_valid(model=model, loss_func=loss_func,\n",
        "                optimizer=optimizer, train_dataloader=train_dataloader,\n",
        "                valid_dataloader=valid_dataloader)"
      ],
      "metadata": {
        "id": "IncsXBnbDyl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b030cf84-0633-41f3-939b-d853169a3ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Epoch 1\n",
            "Training loss 0.004648790694773197\n",
            "Validation loss 0.002274962142109871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing the ML init code\n",
        "\n",
        "Below is the code for the MPNNPredictor from [dgl](https://github.com/awslabs/dgl-lifesci/blob/master/python/dgllife/model/model_zoo/mpnn_predictor.py)"
      ],
      "metadata": {
        "id": "Rg8fHWLrFjEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "import torch.nn as nn\n",
        "\n",
        "from dgl.nn.pytorch import Set2Set\n",
        "\n",
        "from dgllife.model.gnn import MPNNGNN\n",
        "\n",
        "class MPNNPredictor(nn.Module):\n",
        "    \"\"\"MPNN for regression and classification on graphs.\n",
        "\n",
        "    MPNN is introduced in `Neural Message Passing for Quantum Chemistry\n",
        "    <https://arxiv.org/abs/1704.01212>`__.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    node_in_feats : int\n",
        "        Size for the input node features.\n",
        "    edge_in_feats : int\n",
        "        Size for the input edge features.\n",
        "    node_out_feats : int\n",
        "        Size for the output node representations. Default to 64.\n",
        "    edge_hidden_feats : int\n",
        "        Size for the hidden edge representations. Default to 128.\n",
        "    n_tasks : int\n",
        "        Number of tasks, which is also the output size. Default to 1.\n",
        "    num_step_message_passing : int\n",
        "        Number of message passing steps. Default to 6.\n",
        "    num_step_set2set : int\n",
        "        Number of set2set steps. Default to 6.\n",
        "    num_layer_set2set : int\n",
        "        Number of set2set layers. Default to 3.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 node_in_feats,\n",
        "                 edge_in_feats,\n",
        "                 node_out_feats=64,\n",
        "                 edge_hidden_feats=128,\n",
        "                 n_tasks=1,\n",
        "                 num_step_message_passing=6,\n",
        "                 num_step_set2set=6,\n",
        "                 num_layer_set2set=3):\n",
        "        super(MPNNPredictor, self).__init__()\n",
        "\n",
        "        self.gnn = MPNNGNN(node_in_feats=node_in_feats,\n",
        "                           node_out_feats=node_out_feats,\n",
        "                           edge_in_feats=edge_in_feats,\n",
        "                           edge_hidden_feats=edge_hidden_feats,\n",
        "                           num_step_message_passing=num_step_message_passing)\n",
        "        self.readout = Set2Set(input_dim=node_out_feats,\n",
        "                               n_iters=num_step_set2set,\n",
        "                               n_layers=num_layer_set2set)\n",
        "        self.predict = nn.Sequential(\n",
        "            nn.Linear(2 * node_out_feats, node_out_feats),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(node_out_feats, n_tasks)\n",
        "        )\n",
        "\n",
        "    def forward(self, g, node_feats, edge_feats):\n",
        "        \"\"\"Graph-level regression/soft classification.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        g : DGLGraph\n",
        "            DGLGraph for a batch of graphs.\n",
        "        node_feats : float32 tensor of shape (V, node_in_feats)\n",
        "            Input node features.\n",
        "        edge_feats : float32 tensor of shape (E, edge_in_feats)\n",
        "            Input edge features.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float32 tensor of shape (G, n_tasks)\n",
        "            Prediction for the graphs in the batch. G for the number of graphs.\n",
        "        \"\"\"\n",
        "        node_feats = self.gnn(g, node_feats, edge_feats)\n",
        "        graph_feats = self.readout(g, node_feats)\n",
        "        return self.predict(graph_feats)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "BE4Q6mHaE3ND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we want to add one more `Linear` layer to the *predict* with `ReLU` activation. We copy paste the entire class and make that change.\n",
        "\n",
        "We will call the model *MPNN_modified*"
      ],
      "metadata": {
        "id": "UzWvNmQNHPaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the import statements\n",
        "import torch.nn as nn\n",
        "from dgl.nn.pytorch import Set2Set\n",
        "from dgllife.model.gnn import MPNNGNN\n",
        "\n",
        "# creating the class; change the class name\n",
        "class MPNN_modified(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 node_in_feats,\n",
        "                 edge_in_feats,\n",
        "                 node_out_feats=64,\n",
        "                 edge_hidden_feats=128,\n",
        "                 n_tasks=1,\n",
        "                 num_step_message_passing=6,\n",
        "                 num_step_set2set=6,\n",
        "                 num_layer_set2set=3):\n",
        "\n",
        "        # don't forget to change the class name in super\n",
        "        super(MPNN_modified, self).__init__()\n",
        "\n",
        "        self.gnn = MPNNGNN(node_in_feats=node_in_feats,\n",
        "                           node_out_feats=node_out_feats,\n",
        "                           edge_in_feats=edge_in_feats,\n",
        "                           edge_hidden_feats=edge_hidden_feats,\n",
        "                           num_step_message_passing=num_step_message_passing)\n",
        "        self.readout = Set2Set(input_dim=node_out_feats,\n",
        "                               n_iters=num_step_set2set,\n",
        "                               n_layers=num_layer_set2set)\n",
        "        self.predict = nn.Sequential(\n",
        "            nn.Linear(2 * node_out_feats, node_out_feats),\n",
        "            nn.ReLU(),\n",
        "\n",
        "\n",
        "            #################################\n",
        "            # let's add a linear layer followed by ReLU\n",
        "            # the input size should match the output of previous layer\n",
        "            nn.Linear(node_out_feats, 2 * node_out_feats),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            ######################################\n",
        "            nn.Linear(2 * node_out_feats, n_tasks)\n",
        "        )\n",
        "\n",
        "    # No change here as we did not change the gnn, readout or predict inputs\n",
        "    def forward(self, g, node_feats, edge_feats):\n",
        "\n",
        "        node_feats = self.gnn(g, node_feats, edge_feats)\n",
        "        graph_feats = self.readout(g, node_feats)\n",
        "        return self.predict(graph_feats)"
      ],
      "metadata": {
        "id": "YbDMUE4PEIdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can train this ML model. The model parameters have not changed. So, we can use the same parameters as before."
      ],
      "metadata": {
        "id": "Lorxp29rJpBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the atom feature length is 74 and bond is 12\n",
        "model = MPNN_modified(node_in_feats = 74,\n",
        "                      edge_in_feats = 12,\n",
        "                      node_out_feats = 64,\n",
        "                      edge_hidden_feats = 128,\n",
        "                      n_tasks = 1,\n",
        "                      num_step_message_passing = 6,\n",
        "                      num_step_set2set = 6,\n",
        "                      num_layer_set2set = 3)\n",
        "\n",
        "# adam optimier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "run_train_valid(model=model, loss_func=loss_func,\n",
        "                optimizer=optimizer, train_dataloader=train_dataloader,\n",
        "                valid_dataloader=valid_dataloader)"
      ],
      "metadata": {
        "id": "uafT-lRgJtVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdaa5433-18cd-4af1-b678-0be298f561c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Epoch 1\n",
            "Training loss 0.0036393736954778433\n",
            "Validation loss 0.0022534511517733335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training code works! Suppose we wanted to control the number of linear layers added using a argument to the model, for example, *num_linear_layers*.\n",
        "\n",
        "We will do that in the following code"
      ],
      "metadata": {
        "id": "5_px-j-bKgAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the import statements\n",
        "import torch.nn as nn\n",
        "from dgl.nn.pytorch import Set2Set\n",
        "from dgllife.model.gnn import MPNNGNN\n",
        "\n",
        "# creating the class; change the class name\n",
        "class MPNN_modified(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 node_in_feats,\n",
        "                 edge_in_feats,\n",
        "                 node_out_feats=64,\n",
        "                 edge_hidden_feats=128,\n",
        "                 n_tasks=1,\n",
        "                 num_step_message_passing=6,\n",
        "                 num_step_set2set=6,\n",
        "                 num_layer_set2set=3,\n",
        "                 # add the num_linear_layers\n",
        "                 num_linear_layers = 1\n",
        "                 ):\n",
        "\n",
        "        # don't forget to change the class name in super\n",
        "        super(MPNN_modified, self).__init__()\n",
        "\n",
        "        self.gnn = MPNNGNN(node_in_feats=node_in_feats,\n",
        "                           node_out_feats=node_out_feats,\n",
        "                           edge_in_feats=edge_in_feats,\n",
        "                           edge_hidden_feats=edge_hidden_feats,\n",
        "                           num_step_message_passing=num_step_message_passing)\n",
        "\n",
        "        self.readout = Set2Set(input_dim=node_out_feats,\n",
        "                               n_iters=num_step_set2set,\n",
        "                               n_layers=num_layer_set2set)\n",
        "\n",
        "        ######################################\n",
        "        # we can use a for loop to add desired number of layers\n",
        "        layers = []\n",
        "        for i in range(num_linear_layers):\n",
        "              layers.append(nn.Linear(node_out_feats, node_out_feats))\n",
        "              layers.append(nn.ReLU())\n",
        "\n",
        "        ######################################\n",
        "\n",
        "        self.predict = nn.Sequential(\n",
        "            nn.Linear(2 * node_out_feats, node_out_feats),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            ## adding the linear layers\n",
        "            nn.Sequential(*layers),\n",
        "\n",
        "            nn.Linear(node_out_feats, n_tasks)\n",
        "        )\n",
        "\n",
        "    # No change here as we did not change the gnn, readout or predict inputs\n",
        "    def forward(self, g, node_feats, edge_feats):\n",
        "\n",
        "        node_feats = self.gnn(g, node_feats, edge_feats)\n",
        "        graph_feats = self.readout(g, node_feats)\n",
        "        return self.predict(graph_feats)"
      ],
      "metadata": {
        "id": "cAPfKsjdJ-Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the `model.predict` with `num_linear_layers` set to 1"
      ],
      "metadata": {
        "id": "uDbcppmqMcG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MPNN_modified(node_in_feats = 74,\n",
        "                      edge_in_feats = 12,\n",
        "                      node_out_feats = 64,\n",
        "                      edge_hidden_feats = 128,\n",
        "                      n_tasks = 1,\n",
        "                      num_step_message_passing = 6,\n",
        "                      num_step_set2set = 6,\n",
        "                      num_layer_set2set = 3,\n",
        "                      num_linear_layers=1)\n",
        "model.predict\n"
      ],
      "metadata": {
        "id": "wrr5Pp8zMdsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add 3 layers and train the model"
      ],
      "metadata": {
        "id": "Mrx3wi6jNG3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MPNN_modified(node_in_feats = 74,\n",
        "                      edge_in_feats = 12,\n",
        "                      node_out_feats = 64,\n",
        "                      edge_hidden_feats = 128,\n",
        "                      n_tasks = 1,\n",
        "                      num_step_message_passing = 6,\n",
        "                      num_step_set2set = 6,\n",
        "                      num_layer_set2set = 3,\n",
        "                      num_linear_layers=3)\n",
        "model.predict\n"
      ],
      "metadata": {
        "id": "TpIUrHSKMlxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9017ed-2565-4f37-bafa-5608dd84c2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "  )\n",
              "  (3): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adam optimier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "run_train_valid(model=model, loss_func=loss_func,\n",
        "                optimizer=optimizer, train_dataloader=train_dataloader,\n",
        "                valid_dataloader=valid_dataloader)"
      ],
      "metadata": {
        "id": "vy9ITZB-NN0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8650f436-a46b-4706-f010-b054fe1720ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Epoch 1\n",
            "Training loss 0.0044091204181313515\n",
            "Validation loss 0.002272021258249879\n",
            "\n",
            "Starting Epoch 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changes to forward function\n",
        "\n",
        "In a published [article](https://pubs.acs.org/doi/10.1021/acs.jcim.9b00237) addiding fingerprints or descriptors to the output from readout layer was found to increase the prediction accuracy"
      ],
      "metadata": {
        "id": "2LWHMFUzOkWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "crvE-M44LoG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In such cases, we will need to modify the `forward` to take in the descriptors/fingerprints. Here, for sake of simplicity, we will just modify the `forward` function to multiply the output readout by a constant  "
      ],
      "metadata": {
        "id": "SiERCI31MHI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the import statements\n",
        "import torch.nn as nn\n",
        "from dgl.nn.pytorch import Set2Set\n",
        "from dgllife.model.gnn import MPNNGNN\n",
        "\n",
        "# creating the class; change the class name\n",
        "class MPNN_modified(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 node_in_feats,\n",
        "                 edge_in_feats,\n",
        "                 node_out_feats=64,\n",
        "                 edge_hidden_feats=128,\n",
        "                 n_tasks=1,\n",
        "                 num_step_message_passing=6,\n",
        "                 num_step_set2set=6,\n",
        "                 num_layer_set2set=3,\n",
        "                 ):\n",
        "\n",
        "        # don't forget to change the class name in super\n",
        "        super(MPNN_modified, self).__init__()\n",
        "\n",
        "        self.gnn = MPNNGNN(node_in_feats=node_in_feats,\n",
        "                           node_out_feats=node_out_feats,\n",
        "                           edge_in_feats=edge_in_feats,\n",
        "                           edge_hidden_feats=edge_hidden_feats,\n",
        "                           num_step_message_passing=num_step_message_passing)\n",
        "        self.readout = Set2Set(input_dim=node_out_feats,\n",
        "                               n_iters=num_step_set2set,\n",
        "                               n_layers=num_layer_set2set)\n",
        "\n",
        "        self.predict = nn.Sequential(\n",
        "            nn.Linear(2 * node_out_feats, node_out_feats),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(node_out_feats, n_tasks)\n",
        "        )\n",
        "\n",
        "    # take in to constant value and multiply the readout output\n",
        "    def forward(self, g, node_feats, edge_feats, constant):\n",
        "\n",
        "        node_feats = self.gnn(g, node_feats, edge_feats)\n",
        "        graph_feats = self.readout(g, node_feats)\n",
        "\n",
        "        #############################################\n",
        "        print(\"Old\",graph_feats,flush=True)\n",
        "\n",
        "        # do the multiplication\n",
        "        new_graph_feats = graph_feats * torch.tensor(constant)\n",
        "\n",
        "        print(\"New\",new_graph_feats,flush=True)\n",
        "\n",
        "        #################################################\n",
        "\n",
        "        return self.predict(new_graph_feats)"
      ],
      "metadata": {
        "id": "f0ywYtZ3NWnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train this model. You will not see any changes in the model itself."
      ],
      "metadata": {
        "id": "nb0uw3-QNTkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MPNN_modified(node_in_feats = 74,\n",
        "                      edge_in_feats = 12,\n",
        "                      node_out_feats = 64,\n",
        "                      edge_hidden_feats = 128,\n",
        "                      n_tasks = 1,\n",
        "                      num_step_message_passing = 6,\n",
        "                      num_step_set2set = 6,\n",
        "                      num_layer_set2set = 3\n",
        ")\n",
        "model\n"
      ],
      "metadata": {
        "id": "oWO34mInNZjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98274ba4-b812-4e93-d6f1-ec4ad9ef90b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MPNN_modified(\n",
              "  (gnn): MPNNGNN(\n",
              "    (project_node_feats): Sequential(\n",
              "      (0): Linear(in_features=74, out_features=64, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (gnn_layer): NNConv(\n",
              "      (edge_func): Sequential(\n",
              "        (0): Linear(in_features=12, out_features=128, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=128, out_features=4096, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (gru): GRU(64, 64)\n",
              "  )\n",
              "  (readout): Set2Set(\n",
              "    n_iters=6\n",
              "    (lstm): LSTM(128, 64, num_layers=3)\n",
              "  )\n",
              "  (predict): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will have to change the `run_train_valid` function to include the constant as input to the model"
      ],
      "metadata": {
        "id": "CXZwi2xcNpKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_train_valid_modified(model, optimizer, loss_func,\n",
        "                    train_dataloader, valid_dataloader):\n",
        "\n",
        "      epochs = 1\n",
        "\n",
        "      # loop over epochs\n",
        "      for epoch in range(epochs):\n",
        "        print(\"\\nStarting Epoch\", epoch+1)\n",
        "\n",
        "        # set the model to train so the parameters can be updated\n",
        "        model.train()\n",
        "        # loop over training batches\n",
        "\n",
        "        train_loss = []\n",
        "        for batch in train_dataloader:\n",
        "\n",
        "          # Do a forward pass\n",
        "          batch_graph, target = batch\n",
        "\n",
        "          # look at the forward function for input\n",
        "          # this model needs graph, node_feats and edge_feats\n",
        "          node_feats = batch_graph.ndata[\"hv\"]\n",
        "          edge_feats = batch_graph.edata[\"he\"]\n",
        "\n",
        "          ###################################################\n",
        "          # adding the constant\n",
        "          predictions = model(batch_graph, node_feats, edge_feats, 10)\n",
        "          ######################################################\n",
        "\n",
        "\n",
        "          # Compute loss\n",
        "          loss = (loss_func(predictions, target)).mean()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Do back propogation and update gradient\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # save loss to compute average loss\n",
        "          train_loss.append(loss)\n",
        "\n",
        "        print(\"Training loss\", torch.tensor(train_loss).mean().item())\n",
        "\n",
        "\n",
        "\n",
        "        # set the model to eval so the parameters are not updated\n",
        "        model.eval()\n",
        "        valid_loss = []\n",
        "\n",
        "        # loop over validation batches\n",
        "        with torch.no_grad():\n",
        "          for batch in valid_dataloader:\n",
        "\n",
        "            # Do a forward pass\n",
        "            batch_graph, target = batch\n",
        "            node_feats = batch_graph.ndata[\"hv\"]\n",
        "            edge_feats = batch_graph.edata[\"he\"]\n",
        "\n",
        "            #####################################################\n",
        "            # adding the constant\n",
        "            predictions = model(batch_graph, node_feats, edge_feats, 10)\n",
        "            #######################################################\n",
        "\n",
        "            # Compute loss and gradient\n",
        "            loss = (loss_func(predictions, target)).mean()\n",
        "\n",
        "            # save loss to compute average loss\n",
        "            valid_loss.append(loss)\n",
        "\n",
        "        print(\"Validation loss\", torch.tensor(valid_loss).mean().item())\n"
      ],
      "metadata": {
        "id": "ECWrVBCgNclF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally train the model"
      ],
      "metadata": {
        "id": "H9KXWbmVOLnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adam optimier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training the model\n",
        "run_train_valid_modified(model=model, loss_func=loss_func,\n",
        "                optimizer=optimizer, train_dataloader=train_dataloader,\n",
        "                valid_dataloader=valid_dataloader)"
      ],
      "metadata": {
        "id": "5SpP5OWiOGcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664484a6-58af-4a87-f6ef-114cda1e1752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Epoch 1\n",
            "Old tensor([[-0.0191,  0.0226, -0.0428,  ..., -0.2088,  0.2327, -0.1983],\n",
            "        [-0.0196,  0.0232, -0.0451,  ..., -0.1662,  0.0935, -0.0936],\n",
            "        [-0.0195,  0.0236, -0.0461,  ..., -0.1559,  0.0519, -0.0499],\n",
            "        ...,\n",
            "        [-0.0199,  0.0235, -0.0465,  ..., -0.1237,  0.0527, -0.0588],\n",
            "        [-0.0218,  0.0226, -0.0464,  ...,  0.0177,  0.1372, -0.0592],\n",
            "        [-0.0196,  0.0224, -0.0430,  ..., -0.1953,  0.2077, -0.1848]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.1907,  0.2262, -0.4278,  ..., -2.0879,  2.3266, -1.9825],\n",
            "        [-0.1959,  0.2318, -0.4510,  ..., -1.6625,  0.9347, -0.9364],\n",
            "        [-0.1953,  0.2356, -0.4607,  ..., -1.5594,  0.5193, -0.4987],\n",
            "        ...,\n",
            "        [-0.1991,  0.2348, -0.4652,  ..., -1.2373,  0.5275, -0.5876],\n",
            "        [-0.2176,  0.2256, -0.4636,  ...,  0.1772,  1.3723, -0.5919],\n",
            "        [-0.1961,  0.2236, -0.4298,  ..., -1.9531,  2.0771, -1.8477]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0197,  0.0314, -0.0499,  ..., -0.1100,  0.2060, -0.1147],\n",
            "        [-0.0184,  0.0312, -0.0477,  ..., -0.0943,  0.3972, -0.1813],\n",
            "        [-0.0193,  0.0314, -0.0490,  ..., -0.0945,  0.2961, -0.1472],\n",
            "        ...,\n",
            "        [-0.0196,  0.0313, -0.0510,  ...,  0.0348,  0.1379,  0.0286],\n",
            "        [-0.0189,  0.0315, -0.0488,  ..., -0.1070,  0.3035, -0.1555],\n",
            "        [-0.0191,  0.0318, -0.0503,  ...,  0.0608,  0.1574,  0.0026]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.1974,  0.3144, -0.4987,  ..., -1.0999,  2.0597, -1.1468],\n",
            "        [-0.1839,  0.3122, -0.4771,  ..., -0.9430,  3.9716, -1.8125],\n",
            "        [-0.1932,  0.3143, -0.4897,  ..., -0.9447,  2.9610, -1.4720],\n",
            "        ...,\n",
            "        [-0.1965,  0.3130, -0.5099,  ...,  0.3477,  1.3788,  0.2862],\n",
            "        [-0.1889,  0.3154, -0.4880,  ..., -1.0702,  3.0351, -1.5553],\n",
            "        [-0.1906,  0.3180, -0.5033,  ...,  0.6080,  1.5737,  0.0261]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0235,  0.0306, -0.0476,  ...,  0.0957,  0.1698,  0.0281],\n",
            "        [-0.0237,  0.0308, -0.0507,  ...,  0.0281,  0.0719,  0.1758],\n",
            "        [-0.0231,  0.0307, -0.0492,  ...,  0.0187,  0.0820,  0.0220],\n",
            "        ...,\n",
            "        [-0.0240,  0.0307, -0.0507,  ...,  0.0392,  0.0798,  0.1367],\n",
            "        [-0.0237,  0.0308, -0.0470,  ...,  0.1575,  0.2269,  0.0395],\n",
            "        [-0.0232,  0.0307, -0.0484,  ...,  0.0607,  0.1179,  0.0477]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2355,  0.3064, -0.4761,  ...,  0.9570,  1.6982,  0.2809],\n",
            "        [-0.2370,  0.3082, -0.5067,  ...,  0.2806,  0.7191,  1.7585],\n",
            "        [-0.2311,  0.3065, -0.4915,  ...,  0.1874,  0.8195,  0.2205],\n",
            "        ...,\n",
            "        [-0.2395,  0.3075, -0.5073,  ...,  0.3917,  0.7982,  1.3670],\n",
            "        [-0.2368,  0.3075, -0.4701,  ...,  1.5753,  2.2687,  0.3954],\n",
            "        [-0.2315,  0.3067, -0.4838,  ...,  0.6066,  1.1787,  0.4772]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0254,  0.0304, -0.0480,  ...,  0.1837,  0.1526,  0.1039],\n",
            "        [-0.0253,  0.0307, -0.0512,  ...,  0.0161,  0.0706,  0.1937],\n",
            "        [-0.0248,  0.0304, -0.0488,  ...,  0.1482,  0.1128,  0.0888],\n",
            "        ...,\n",
            "        [-0.0244,  0.0305, -0.0492,  ...,  0.0407,  0.0454,  0.0692],\n",
            "        [-0.0246,  0.0305, -0.0492,  ...,  0.0659,  0.0647,  0.0639],\n",
            "        [-0.0249,  0.0304, -0.0481,  ...,  0.1518,  0.1251,  0.0811]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2539,  0.3037, -0.4801,  ...,  1.8369,  1.5263,  1.0390],\n",
            "        [-0.2532,  0.3074, -0.5121,  ...,  0.1614,  0.7065,  1.9365],\n",
            "        [-0.2480,  0.3040, -0.4881,  ...,  1.4820,  1.1276,  0.8876],\n",
            "        ...,\n",
            "        [-0.2439,  0.3047, -0.4918,  ...,  0.4074,  0.4542,  0.6923],\n",
            "        [-0.2456,  0.3053, -0.4921,  ...,  0.6591,  0.6468,  0.6392],\n",
            "        [-0.2490,  0.3036, -0.4808,  ...,  1.5183,  1.2514,  0.8107]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0268,  0.0319, -0.0489,  ...,  0.1768,  0.1297,  0.1122],\n",
            "        [-0.0259,  0.0317, -0.0498,  ...,  0.1040,  0.0728,  0.0879],\n",
            "        [-0.0253,  0.0315, -0.0506,  ...,  0.0805,  0.0581,  0.0767],\n",
            "        ...,\n",
            "        [-0.0265,  0.0318, -0.0495,  ...,  0.1794,  0.1500,  0.0798],\n",
            "        [-0.0261,  0.0317, -0.0519,  ..., -0.0411,  0.0910,  0.2104],\n",
            "        [-0.0255,  0.0316, -0.0502,  ...,  0.0412,  0.0362,  0.0655]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2685,  0.3186, -0.4889,  ...,  1.7684,  1.2973,  1.1218],\n",
            "        [-0.2592,  0.3167, -0.4985,  ...,  1.0402,  0.7281,  0.8794],\n",
            "        [-0.2531,  0.3152, -0.5057,  ...,  0.8049,  0.5813,  0.7666],\n",
            "        ...,\n",
            "        [-0.2654,  0.3181, -0.4952,  ...,  1.7935,  1.5005,  0.7979],\n",
            "        [-0.2614,  0.3174, -0.5190,  ..., -0.4105,  0.9097,  2.1041],\n",
            "        [-0.2553,  0.3164, -0.5020,  ...,  0.4122,  0.3619,  0.6552]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0263,  0.0327, -0.0512,  ...,  0.0652,  0.0552,  0.0496],\n",
            "        [-0.0279,  0.0333, -0.0509,  ...,  0.1634,  0.1460,  0.0724],\n",
            "        [-0.0263,  0.0326, -0.0517,  ...,  0.0646,  0.0552,  0.0750],\n",
            "        ...,\n",
            "        [-0.0271,  0.0330, -0.0513,  ...,  0.1251,  0.1068,  0.0738],\n",
            "        [-0.0268,  0.0328, -0.0511,  ...,  0.1018,  0.0798,  0.0875],\n",
            "        [-0.0276,  0.0332, -0.0511,  ...,  0.1806,  0.1585,  0.0599]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2632,  0.3266, -0.5117,  ...,  0.6515,  0.5517,  0.4964],\n",
            "        [-0.2787,  0.3329, -0.5086,  ...,  1.6341,  1.4597,  0.7237],\n",
            "        [-0.2625,  0.3260, -0.5167,  ...,  0.6460,  0.5517,  0.7497],\n",
            "        ...,\n",
            "        [-0.2710,  0.3299, -0.5133,  ...,  1.2509,  1.0683,  0.7378],\n",
            "        [-0.2682,  0.3278, -0.5110,  ...,  1.0180,  0.7977,  0.8746],\n",
            "        [-0.2757,  0.3322, -0.5107,  ...,  1.8064,  1.5853,  0.5990]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0278,  0.0336, -0.0516,  ...,  0.0907,  0.0831,  0.0904],\n",
            "        [-0.0278,  0.0333, -0.0517,  ...,  0.0743,  0.0664,  0.0993],\n",
            "        [-0.0281,  0.0333, -0.0525,  ..., -0.0530,  0.0962,  0.2066],\n",
            "        ...,\n",
            "        [-0.0264,  0.0328, -0.0523,  ...,  0.0401,  0.0464,  0.0645],\n",
            "        [-0.0274,  0.0334, -0.0517,  ...,  0.0867,  0.0753,  0.0725],\n",
            "        [-0.0274,  0.0330, -0.0522,  ...,  0.0613,  0.0801,  0.0956]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2777,  0.3356, -0.5156,  ...,  0.9072,  0.8314,  0.9042],\n",
            "        [-0.2778,  0.3329, -0.5169,  ...,  0.7432,  0.6645,  0.9930],\n",
            "        [-0.2805,  0.3332, -0.5251,  ..., -0.5301,  0.9624,  2.0662],\n",
            "        ...,\n",
            "        [-0.2640,  0.3280, -0.5228,  ...,  0.4012,  0.4644,  0.6454],\n",
            "        [-0.2737,  0.3343, -0.5166,  ...,  0.8673,  0.7528,  0.7247],\n",
            "        [-0.2743,  0.3298, -0.5222,  ...,  0.6127,  0.8013,  0.9563]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0263,  0.0325, -0.0527,  ..., -0.0068,  0.0272,  0.0654],\n",
            "        [-0.0292,  0.0335, -0.0520,  ..., -0.0912,  0.0941,  0.2554],\n",
            "        [-0.0279,  0.0333, -0.0520,  ...,  0.0333,  0.0470,  0.1039],\n",
            "        ...,\n",
            "        [-0.0269,  0.0329, -0.0520,  ...,  0.0152,  0.0221,  0.0681],\n",
            "        [-0.0294,  0.0336, -0.0519,  ..., -0.0854,  0.1043,  0.2679],\n",
            "        [-0.0264,  0.0326, -0.0526,  ...,  0.0006,  0.0250,  0.0575]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2630,  0.3248, -0.5274,  ..., -0.0676,  0.2724,  0.6543],\n",
            "        [-0.2922,  0.3353, -0.5203,  ..., -0.9122,  0.9408,  2.5536],\n",
            "        [-0.2788,  0.3330, -0.5197,  ...,  0.3334,  0.4702,  1.0388],\n",
            "        ...,\n",
            "        [-0.2692,  0.3293, -0.5196,  ...,  0.1518,  0.2215,  0.6813],\n",
            "        [-0.2943,  0.3365, -0.5192,  ..., -0.8540,  1.0432,  2.6790],\n",
            "        [-0.2642,  0.3256, -0.5257,  ...,  0.0061,  0.2498,  0.5752]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0270,  0.0326, -0.0527,  ..., -0.0130,  0.0224,  0.0665],\n",
            "        [-0.0298,  0.0337, -0.0522,  ..., -0.0951,  0.0810,  0.2705],\n",
            "        [-0.0274,  0.0328, -0.0524,  ..., -0.0107,  0.0073,  0.0952],\n",
            "        ...,\n",
            "        [-0.0275,  0.0326, -0.0526,  ..., -0.0311, -0.0062,  0.1125],\n",
            "        [-0.0272,  0.0327, -0.0525,  ..., -0.0239,  0.0173,  0.0739],\n",
            "        [-0.0268,  0.0325, -0.0525,  ..., -0.0088,  0.0172,  0.0578]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2700,  0.3260, -0.5270,  ..., -0.1302,  0.2245,  0.6648],\n",
            "        [-0.2975,  0.3368, -0.5222,  ..., -0.9512,  0.8096,  2.7054],\n",
            "        [-0.2736,  0.3276, -0.5238,  ..., -0.1074,  0.0726,  0.9524],\n",
            "        ...,\n",
            "        [-0.2748,  0.3261, -0.5261,  ..., -0.3107, -0.0623,  1.1255],\n",
            "        [-0.2725,  0.3274, -0.5246,  ..., -0.2390,  0.1729,  0.7390],\n",
            "        [-0.2682,  0.3251, -0.5246,  ..., -0.0882,  0.1723,  0.5777]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-2.7372e-02,  3.2551e-02, -5.3065e-02,  ..., -2.5358e-02,\n",
            "         -1.0791e-04,  7.7244e-02],\n",
            "        [-2.9956e-02,  3.3725e-02, -5.2492e-02,  ..., -2.3948e-02,\n",
            "          6.4123e-02,  2.0970e-01],\n",
            "        [-2.7618e-02,  3.2468e-02, -5.3255e-02,  ..., -4.5435e-02,\n",
            "         -1.0732e-02,  9.2902e-02],\n",
            "        ...,\n",
            "        [-2.7263e-02,  3.2290e-02, -5.3232e-02,  ..., -5.6810e-02,\n",
            "         -1.5355e-02,  9.1727e-02],\n",
            "        [-2.7484e-02,  3.2348e-02, -5.2989e-02,  ..., -7.2584e-02,\n",
            "         -2.0248e-02,  9.2256e-02],\n",
            "        [-2.7213e-02,  3.2488e-02, -5.2995e-02,  ..., -4.0485e-02,\n",
            "         -1.0165e-02,  8.8639e-02]], grad_fn=<CatBackward0>)\n",
            "New tensor([[-2.7372e-01,  3.2551e-01, -5.3065e-01,  ..., -2.5358e-01,\n",
            "         -1.0791e-03,  7.7244e-01],\n",
            "        [-2.9956e-01,  3.3725e-01, -5.2492e-01,  ..., -2.3948e-01,\n",
            "          6.4123e-01,  2.0970e+00],\n",
            "        [-2.7618e-01,  3.2468e-01, -5.3255e-01,  ..., -4.5435e-01,\n",
            "         -1.0732e-01,  9.2902e-01],\n",
            "        ...,\n",
            "        [-2.7263e-01,  3.2290e-01, -5.3232e-01,  ..., -5.6810e-01,\n",
            "         -1.5355e-01,  9.1727e-01],\n",
            "        [-2.7484e-01,  3.2348e-01, -5.2989e-01,  ..., -7.2584e-01,\n",
            "         -2.0248e-01,  9.2256e-01],\n",
            "        [-2.7213e-01,  3.2488e-01, -5.2995e-01,  ..., -4.0485e-01,\n",
            "         -1.0165e-01,  8.8639e-01]], grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0312,  0.0340, -0.0521,  ..., -0.0021,  0.0769,  0.2248],\n",
            "        [-0.0274,  0.0324, -0.0536,  ..., -0.0502, -0.0303,  0.0813],\n",
            "        [-0.0343,  0.0359, -0.0499,  ...,  0.0422,  0.1263,  0.4021],\n",
            "        ...,\n",
            "        [-0.0279,  0.0326, -0.0535,  ..., -0.0381,  0.0108,  0.0834],\n",
            "        [-0.0276,  0.0325, -0.0537,  ..., -0.0366,  0.0022,  0.0724],\n",
            "        [-0.0275,  0.0325, -0.0535,  ..., -0.0496, -0.0228,  0.0733]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.3121,  0.3402, -0.5211,  ..., -0.0214,  0.7692,  2.2476],\n",
            "        [-0.2744,  0.3244, -0.5363,  ..., -0.5024, -0.3034,  0.8135],\n",
            "        [-0.3435,  0.3586, -0.4988,  ...,  0.4216,  1.2628,  4.0214],\n",
            "        ...,\n",
            "        [-0.2789,  0.3261, -0.5349,  ..., -0.3814,  0.1079,  0.8345],\n",
            "        [-0.2760,  0.3255, -0.5366,  ..., -0.3661,  0.0221,  0.7240],\n",
            "        [-0.2754,  0.3248, -0.5351,  ..., -0.4956, -0.2284,  0.7333]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0277,  0.0327, -0.0534,  ..., -0.0174,  0.0100,  0.0612],\n",
            "        [-0.0278,  0.0326, -0.0536,  ..., -0.0566, -0.0346,  0.0696],\n",
            "        [-0.0278,  0.0325, -0.0539,  ..., -0.0585, -0.0312,  0.0744],\n",
            "        ...,\n",
            "        [-0.0280,  0.0325, -0.0538,  ..., -0.0741, -0.0391,  0.0798],\n",
            "        [-0.0279,  0.0325, -0.0537,  ..., -0.0806, -0.0571,  0.0846],\n",
            "        [-0.0277,  0.0324, -0.0537,  ..., -0.0833, -0.0527,  0.0847]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2771,  0.3274, -0.5344,  ..., -0.1741,  0.1003,  0.6124],\n",
            "        [-0.2781,  0.3258, -0.5357,  ..., -0.5663, -0.3462,  0.6963],\n",
            "        [-0.2779,  0.3249, -0.5388,  ..., -0.5850, -0.3124,  0.7440],\n",
            "        ...,\n",
            "        [-0.2797,  0.3249, -0.5377,  ..., -0.7409, -0.3909,  0.7977],\n",
            "        [-0.2790,  0.3251, -0.5366,  ..., -0.8064, -0.5711,  0.8457],\n",
            "        [-0.2770,  0.3243, -0.5367,  ..., -0.8330, -0.5274,  0.8471]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0281,  0.0327, -0.0540,  ..., -0.0597, -0.0243,  0.0763],\n",
            "        [-0.0280,  0.0329, -0.0538,  ..., -0.0376,  0.0047,  0.0877],\n",
            "        [-0.0281,  0.0325, -0.0545,  ..., -0.0899, -0.0582,  0.0854],\n",
            "        ...,\n",
            "        [-0.0310,  0.0342, -0.0529,  ..., -0.0499,  0.0311,  0.2650],\n",
            "        [-0.0279,  0.0327, -0.0536,  ..., -0.0493, -0.0072,  0.0606],\n",
            "        [-0.0281,  0.0324, -0.0543,  ..., -0.1024, -0.0740,  0.0893]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2811,  0.3273, -0.5395,  ..., -0.5974, -0.2430,  0.7635],\n",
            "        [-0.2801,  0.3287, -0.5384,  ..., -0.3761,  0.0473,  0.8765],\n",
            "        [-0.2815,  0.3249, -0.5452,  ..., -0.8989, -0.5815,  0.8537],\n",
            "        ...,\n",
            "        [-0.3100,  0.3424, -0.5288,  ..., -0.4990,  0.3113,  2.6500],\n",
            "        [-0.2793,  0.3271, -0.5357,  ..., -0.4933, -0.0723,  0.6062],\n",
            "        [-0.2809,  0.3242, -0.5431,  ..., -1.0237, -0.7401,  0.8931]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0315,  0.0346, -0.0523,  ..., -0.0682,  0.0417,  0.2963],\n",
            "        [-0.0279,  0.0326, -0.0539,  ..., -0.0780, -0.0485,  0.0714],\n",
            "        [-0.0284,  0.0325, -0.0540,  ..., -0.1277, -0.0694,  0.1047],\n",
            "        ...,\n",
            "        [-0.0283,  0.0326, -0.0538,  ..., -0.1013, -0.0489,  0.0905],\n",
            "        [-0.0280,  0.0328, -0.0534,  ..., -0.0236,  0.0023,  0.0427],\n",
            "        [-0.0281,  0.0329, -0.0540,  ..., -0.0372,  0.0008,  0.0719]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.3150,  0.3455, -0.5226,  ..., -0.6820,  0.4174,  2.9633],\n",
            "        [-0.2795,  0.3255, -0.5386,  ..., -0.7803, -0.4848,  0.7137],\n",
            "        [-0.2836,  0.3253, -0.5398,  ..., -1.2767, -0.6942,  1.0471],\n",
            "        ...,\n",
            "        [-0.2825,  0.3258, -0.5378,  ..., -1.0128, -0.4891,  0.9051],\n",
            "        [-0.2804,  0.3284, -0.5340,  ..., -0.2355,  0.0230,  0.4269],\n",
            "        [-0.2810,  0.3288, -0.5395,  ..., -0.3716,  0.0075,  0.7191]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0282,  0.0324, -0.0543,  ..., -0.1294, -0.0803,  0.0938],\n",
            "        [-0.0283,  0.0327, -0.0539,  ..., -0.0903, -0.0284,  0.0878],\n",
            "        [-0.0286,  0.0329, -0.0541,  ..., -0.0645,  0.0071,  0.1023],\n",
            "        ...,\n",
            "        [-0.0283,  0.0325, -0.0546,  ..., -0.1252, -0.0872,  0.0933],\n",
            "        [-0.0287,  0.0328, -0.0543,  ..., -0.0729, -0.0227,  0.0909],\n",
            "        [-0.0283,  0.0328, -0.0540,  ..., -0.0829, -0.0376,  0.0907]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2825,  0.3243, -0.5435,  ..., -1.2940, -0.8026,  0.9382],\n",
            "        [-0.2834,  0.3265, -0.5386,  ..., -0.9035, -0.2838,  0.8781],\n",
            "        [-0.2857,  0.3290, -0.5412,  ..., -0.6448,  0.0705,  1.0232],\n",
            "        ...,\n",
            "        [-0.2826,  0.3249, -0.5462,  ..., -1.2518, -0.8718,  0.9330],\n",
            "        [-0.2867,  0.3283, -0.5429,  ..., -0.7287, -0.2273,  0.9092],\n",
            "        [-0.2835,  0.3280, -0.5404,  ..., -0.8289, -0.3761,  0.9066]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0319,  0.0351, -0.0507,  ..., -0.0199,  0.0438,  0.4451],\n",
            "        [-0.0282,  0.0326, -0.0543,  ..., -0.0707, -0.0491,  0.0710],\n",
            "        [-0.0285,  0.0326, -0.0542,  ..., -0.0902, -0.0487,  0.0822],\n",
            "        ...,\n",
            "        [-0.0282,  0.0326, -0.0545,  ..., -0.0776, -0.0486,  0.0764],\n",
            "        [-0.0286,  0.0327, -0.0543,  ..., -0.0928, -0.0358,  0.1010],\n",
            "        [-0.0287,  0.0326, -0.0544,  ..., -0.1144, -0.0712,  0.1024]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.3186,  0.3515, -0.5067,  ..., -0.1985,  0.4380,  4.4508],\n",
            "        [-0.2821,  0.3265, -0.5430,  ..., -0.7075, -0.4911,  0.7102],\n",
            "        [-0.2852,  0.3259, -0.5421,  ..., -0.9023, -0.4873,  0.8216],\n",
            "        ...,\n",
            "        [-0.2816,  0.3261, -0.5453,  ..., -0.7764, -0.4862,  0.7640],\n",
            "        [-0.2864,  0.3268, -0.5430,  ..., -0.9278, -0.3579,  1.0096],\n",
            "        [-0.2869,  0.3257, -0.5442,  ..., -1.1438, -0.7125,  1.0243]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0286,  0.0325, -0.0537,  ..., -0.0870, -0.0367,  0.0789],\n",
            "        [-0.0284,  0.0325, -0.0545,  ..., -0.0720, -0.0376,  0.0825],\n",
            "        [-0.0282,  0.0322, -0.0547,  ..., -0.1262, -0.0890,  0.0891],\n",
            "        ...,\n",
            "        [-0.0286,  0.0322, -0.0542,  ..., -0.1626, -0.0846,  0.1059],\n",
            "        [-0.0285,  0.0322, -0.0544,  ..., -0.1438, -0.0903,  0.0961],\n",
            "        [-0.0316,  0.0345, -0.0515,  ..., -0.0436,  0.0252,  0.3742]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2856,  0.3250, -0.5373,  ..., -0.8698, -0.3669,  0.7893],\n",
            "        [-0.2838,  0.3253, -0.5451,  ..., -0.7197, -0.3764,  0.8252],\n",
            "        [-0.2822,  0.3223, -0.5467,  ..., -1.2623, -0.8900,  0.8909],\n",
            "        ...,\n",
            "        [-0.2860,  0.3217, -0.5418,  ..., -1.6264, -0.8464,  1.0594],\n",
            "        [-0.2850,  0.3217, -0.5441,  ..., -1.4380, -0.9030,  0.9607],\n",
            "        [-0.3157,  0.3452, -0.5154,  ..., -0.4360,  0.2525,  3.7424]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0286,  0.0320, -0.0545,  ..., -0.1497, -0.0830,  0.1028],\n",
            "        [-0.0284,  0.0323, -0.0541,  ..., -0.0684, -0.0158,  0.0872],\n",
            "        [-0.0281,  0.0321, -0.0539,  ..., -0.0908, -0.0531,  0.0738],\n",
            "        ...,\n",
            "        [-0.0311,  0.0339, -0.0526,  ..., -0.0709,  0.0038,  0.3056],\n",
            "        [-0.0282,  0.0320, -0.0545,  ..., -0.1201, -0.0755,  0.0779],\n",
            "        [-0.0286,  0.0322, -0.0547,  ..., -0.1221, -0.0602,  0.0913]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2860,  0.3204, -0.5452,  ..., -1.4971, -0.8298,  1.0281],\n",
            "        [-0.2844,  0.3226, -0.5408,  ..., -0.6835, -0.1583,  0.8718],\n",
            "        [-0.2815,  0.3212, -0.5393,  ..., -0.9079, -0.5313,  0.7384],\n",
            "        ...,\n",
            "        [-0.3108,  0.3387, -0.5264,  ..., -0.7093,  0.0377,  3.0556],\n",
            "        [-0.2820,  0.3198, -0.5447,  ..., -1.2015, -0.7551,  0.7794],\n",
            "        [-0.2864,  0.3216, -0.5468,  ..., -1.2209, -0.6016,  0.9132]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0284,  0.0319, -0.0537,  ..., -0.1007, -0.0486,  0.0698],\n",
            "        [-0.0291,  0.0319, -0.0547,  ..., -0.1815, -0.0881,  0.1189],\n",
            "        [-0.0284,  0.0319, -0.0546,  ..., -0.1278, -0.0822,  0.0762],\n",
            "        ...,\n",
            "        [-0.0285,  0.0318, -0.0547,  ..., -0.1629, -0.0923,  0.0954],\n",
            "        [-0.0312,  0.0338, -0.0530,  ..., -0.1048,  0.0348,  0.3271],\n",
            "        [-0.0283,  0.0319, -0.0548,  ..., -0.1205, -0.0702,  0.0847]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2841,  0.3189, -0.5374,  ..., -1.0068, -0.4864,  0.6978],\n",
            "        [-0.2910,  0.3191, -0.5469,  ..., -1.8147, -0.8806,  1.1889],\n",
            "        [-0.2840,  0.3190, -0.5460,  ..., -1.2781, -0.8217,  0.7618],\n",
            "        ...,\n",
            "        [-0.2848,  0.3176, -0.5475,  ..., -1.6294, -0.9231,  0.9537],\n",
            "        [-0.3115,  0.3379, -0.5304,  ..., -1.0479,  0.3485,  3.2714],\n",
            "        [-0.2831,  0.3191, -0.5480,  ..., -1.2047, -0.7024,  0.8469]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0286,  0.0319, -0.0548,  ..., -0.1112, -0.0307,  0.1151],\n",
            "        [-0.0286,  0.0318, -0.0536,  ..., -0.1051, -0.0423,  0.0758],\n",
            "        [-0.0282,  0.0316, -0.0544,  ..., -0.1275, -0.0783,  0.0752],\n",
            "        ...,\n",
            "        [-0.0283,  0.0319, -0.0548,  ..., -0.1016, -0.0414,  0.0993],\n",
            "        [-0.0287,  0.0317, -0.0552,  ..., -0.1615, -0.1095,  0.0929],\n",
            "        [-0.0314,  0.0337, -0.0533,  ..., -0.1192,  0.0268,  0.3251]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2859,  0.3189, -0.5482,  ..., -1.1120, -0.3070,  1.1512],\n",
            "        [-0.2862,  0.3180, -0.5361,  ..., -1.0508, -0.4231,  0.7581],\n",
            "        [-0.2817,  0.3162, -0.5437,  ..., -1.2748, -0.7828,  0.7518],\n",
            "        ...,\n",
            "        [-0.2828,  0.3191, -0.5483,  ..., -1.0156, -0.4144,  0.9932],\n",
            "        [-0.2874,  0.3174, -0.5524,  ..., -1.6145, -1.0953,  0.9290],\n",
            "        [-0.3138,  0.3371, -0.5333,  ..., -1.1917,  0.2683,  3.2510]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0312,  0.0336, -0.0549,  ..., -0.1372,  0.0220,  0.3107],\n",
            "        [-0.0287,  0.0315, -0.0546,  ..., -0.1733, -0.0869,  0.0954],\n",
            "        [-0.0283,  0.0316, -0.0545,  ..., -0.1321, -0.0728,  0.0858],\n",
            "        ...,\n",
            "        [-0.0287,  0.0317, -0.0550,  ..., -0.1566, -0.0835,  0.1073],\n",
            "        [-0.0285,  0.0316, -0.0548,  ..., -0.1546, -0.0943,  0.0917],\n",
            "        [-0.0280,  0.0317, -0.0544,  ..., -0.0967, -0.0711,  0.0656]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.3119,  0.3364, -0.5485,  ..., -1.3718,  0.2198,  3.1069],\n",
            "        [-0.2869,  0.3153, -0.5456,  ..., -1.7329, -0.8688,  0.9535],\n",
            "        [-0.2832,  0.3163, -0.5449,  ..., -1.3207, -0.7282,  0.8576],\n",
            "        ...,\n",
            "        [-0.2869,  0.3168, -0.5503,  ..., -1.5659, -0.8349,  1.0726],\n",
            "        [-0.2853,  0.3165, -0.5480,  ..., -1.5459, -0.9432,  0.9171],\n",
            "        [-0.2801,  0.3167, -0.5438,  ..., -0.9673, -0.7112,  0.6562]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0288,  0.0316, -0.0552,  ..., -0.1730, -0.1156,  0.1008],\n",
            "        [-0.0284,  0.0316, -0.0543,  ..., -0.1481, -0.0776,  0.0928],\n",
            "        [-0.0289,  0.0318, -0.0538,  ..., -0.1190, -0.0325,  0.1107],\n",
            "        ...,\n",
            "        [-0.0286,  0.0314, -0.0550,  ..., -0.1848, -0.1015,  0.1003],\n",
            "        [-0.0285,  0.0316, -0.0537,  ..., -0.1094, -0.0539,  0.0788],\n",
            "        [-0.0285,  0.0316, -0.0539,  ..., -0.1147, -0.0583,  0.0806]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2881,  0.3159, -0.5519,  ..., -1.7296, -1.1564,  1.0078],\n",
            "        [-0.2844,  0.3159, -0.5433,  ..., -1.4809, -0.7761,  0.9284],\n",
            "        [-0.2893,  0.3178, -0.5381,  ..., -1.1900, -0.3251,  1.1073],\n",
            "        ...,\n",
            "        [-0.2864,  0.3144, -0.5499,  ..., -1.8478, -1.0152,  1.0028],\n",
            "        [-0.2854,  0.3164, -0.5366,  ..., -1.0935, -0.5393,  0.7881],\n",
            "        [-0.2847,  0.3163, -0.5393,  ..., -1.1474, -0.5832,  0.8064]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0309,  0.0332, -0.0550,  ..., -0.1643, -0.0077,  0.2486],\n",
            "        [-0.0286,  0.0317, -0.0541,  ..., -0.1128, -0.0367,  0.0966],\n",
            "        [-0.0286,  0.0317, -0.0539,  ..., -0.1230, -0.0544,  0.0900],\n",
            "        ...,\n",
            "        [-0.0285,  0.0316, -0.0547,  ..., -0.1368, -0.0707,  0.0931],\n",
            "        [-0.0307,  0.0331, -0.0556,  ..., -0.1646, -0.0233,  0.2558],\n",
            "        [-0.0286,  0.0317, -0.0542,  ..., -0.1219, -0.0466,  0.0960]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.3091,  0.3315, -0.5504,  ..., -1.6426, -0.0766,  2.4859],\n",
            "        [-0.2862,  0.3168, -0.5412,  ..., -1.1276, -0.3671,  0.9664],\n",
            "        [-0.2858,  0.3166, -0.5389,  ..., -1.2296, -0.5440,  0.8996],\n",
            "        ...,\n",
            "        [-0.2850,  0.3164, -0.5471,  ..., -1.3684, -0.7073,  0.9309],\n",
            "        [-0.3065,  0.3313, -0.5560,  ..., -1.6459, -0.2328,  2.5585],\n",
            "        [-0.2855,  0.3167, -0.5418,  ..., -1.2190, -0.4662,  0.9599]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0289,  0.0317, -0.0549,  ..., -0.1157, -0.0154,  0.1462],\n",
            "        [-0.0289,  0.0317, -0.0544,  ..., -0.1461, -0.0548,  0.1078],\n",
            "        [-0.0311,  0.0335, -0.0555,  ..., -0.1822,  0.0137,  0.3080],\n",
            "        ...,\n",
            "        [-0.0287,  0.0314, -0.0543,  ..., -0.1839, -0.0944,  0.1027],\n",
            "        [-0.0287,  0.0315, -0.0550,  ..., -0.1657, -0.0906,  0.1011],\n",
            "        [-0.0284,  0.0317, -0.0551,  ..., -0.1183, -0.0560,  0.0935]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2886,  0.3172, -0.5487,  ..., -1.1569, -0.1543,  1.4618],\n",
            "        [-0.2888,  0.3171, -0.5436,  ..., -1.4609, -0.5485,  1.0782],\n",
            "        [-0.3114,  0.3346, -0.5549,  ..., -1.8217,  0.1373,  3.0796],\n",
            "        ...,\n",
            "        [-0.2873,  0.3142, -0.5435,  ..., -1.8394, -0.9444,  1.0275],\n",
            "        [-0.2866,  0.3150, -0.5496,  ..., -1.6573, -0.9063,  1.0106],\n",
            "        [-0.2842,  0.3172, -0.5506,  ..., -1.1830, -0.5603,  0.9351]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0288,  0.0315, -0.0547,  ..., -0.1702, -0.0886,  0.1104],\n",
            "        [-0.0284,  0.0314, -0.0538,  ..., -0.1182, -0.0541,  0.0783],\n",
            "        [-0.0286,  0.0317, -0.0540,  ..., -0.0912, -0.0212,  0.0965],\n",
            "        ...,\n",
            "        [-0.0285,  0.0314, -0.0541,  ..., -0.1311, -0.0606,  0.0913],\n",
            "        [-0.0308,  0.0330, -0.0554,  ..., -0.1826, -0.0253,  0.2651],\n",
            "        [-0.0309,  0.0334, -0.0558,  ..., -0.1827,  0.0191,  0.3199]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2877,  0.3150, -0.5473,  ..., -1.7025, -0.8857,  1.1044],\n",
            "        [-0.2839,  0.3145, -0.5380,  ..., -1.1818, -0.5406,  0.7825],\n",
            "        [-0.2856,  0.3166, -0.5398,  ..., -0.9117, -0.2115,  0.9646],\n",
            "        ...,\n",
            "        [-0.2850,  0.3143, -0.5408,  ..., -1.3114, -0.6057,  0.9135],\n",
            "        [-0.3081,  0.3299, -0.5540,  ..., -1.8261, -0.2531,  2.6511],\n",
            "        [-0.3087,  0.3344, -0.5582,  ..., -1.8267,  0.1914,  3.1991]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0309,  0.0334, -0.0562,  ..., -0.1878,  0.0124,  0.3314],\n",
            "        [-0.0284,  0.0312, -0.0543,  ..., -0.1806, -0.1015,  0.1023],\n",
            "        [-0.0311,  0.0328, -0.0549,  ..., -0.2047, -0.0444,  0.2582],\n",
            "        ...,\n",
            "        [-0.0282,  0.0311, -0.0545,  ..., -0.1692, -0.1019,  0.0883],\n",
            "        [-0.0286,  0.0313, -0.0539,  ..., -0.1628, -0.0844,  0.0957],\n",
            "        [-0.0287,  0.0314, -0.0548,  ..., -0.1847, -0.1206,  0.1073]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.3089,  0.3337, -0.5619,  ..., -1.8784,  0.1238,  3.3139],\n",
            "        [-0.2843,  0.3121, -0.5426,  ..., -1.8061, -1.0149,  1.0227],\n",
            "        [-0.3114,  0.3285, -0.5485,  ..., -2.0468, -0.4441,  2.5817],\n",
            "        ...,\n",
            "        [-0.2822,  0.3113, -0.5446,  ..., -1.6917, -1.0192,  0.8827],\n",
            "        [-0.2859,  0.3135, -0.5388,  ..., -1.6278, -0.8440,  0.9571],\n",
            "        [-0.2870,  0.3137, -0.5484,  ..., -1.8468, -1.2062,  1.0725]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0286,  0.0314, -0.0540,  ..., -0.1272, -0.0547,  0.0854],\n",
            "        [-0.0286,  0.0313, -0.0543,  ..., -0.1646, -0.0789,  0.1009],\n",
            "        [-0.0286,  0.0314, -0.0536,  ..., -0.1301, -0.0574,  0.0822],\n",
            "        ...,\n",
            "        [-0.0285,  0.0313, -0.0540,  ..., -0.1613, -0.0794,  0.0938],\n",
            "        [-0.0283,  0.0312, -0.0543,  ..., -0.1810, -0.1042,  0.0981],\n",
            "        [-0.0283,  0.0312, -0.0540,  ..., -0.1678, -0.0936,  0.0915]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2858,  0.3139, -0.5396,  ..., -1.2724, -0.5467,  0.8544],\n",
            "        [-0.2863,  0.3132, -0.5429,  ..., -1.6462, -0.7888,  1.0091],\n",
            "        [-0.2861,  0.3138, -0.5356,  ..., -1.3012, -0.5742,  0.8225],\n",
            "        ...,\n",
            "        [-0.2847,  0.3127, -0.5402,  ..., -1.6127, -0.7942,  0.9379],\n",
            "        [-0.2835,  0.3116, -0.5427,  ..., -1.8102, -1.0416,  0.9812],\n",
            "        [-0.2830,  0.3125, -0.5400,  ..., -1.6779, -0.9363,  0.9154]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0302,  0.0326, -0.0556,  ..., -0.1715, -0.0280,  0.2370],\n",
            "        [-0.0309,  0.0332, -0.0559,  ..., -0.2008,  0.0101,  0.3163],\n",
            "        [-0.0286,  0.0313, -0.0539,  ..., -0.1798, -0.0915,  0.0974],\n",
            "        ...,\n",
            "        [-0.0309,  0.0330, -0.0558,  ..., -0.1999,  0.0048,  0.2986],\n",
            "        [-0.0287,  0.0315, -0.0536,  ..., -0.1307, -0.0596,  0.0852],\n",
            "        [-0.0286,  0.0315, -0.0534,  ..., -0.0927, -0.0415,  0.0719]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.3018,  0.3262, -0.5558,  ..., -1.7147, -0.2802,  2.3696],\n",
            "        [-0.3090,  0.3315, -0.5586,  ..., -2.0084,  0.1012,  3.1625],\n",
            "        [-0.2858,  0.3128, -0.5394,  ..., -1.7980, -0.9151,  0.9738],\n",
            "        ...,\n",
            "        [-0.3094,  0.3301, -0.5583,  ..., -1.9994,  0.0477,  2.9864],\n",
            "        [-0.2869,  0.3147, -0.5364,  ..., -1.3071, -0.5962,  0.8519],\n",
            "        [-0.2859,  0.3155, -0.5344,  ..., -0.9272, -0.4152,  0.7189]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0284,  0.0312, -0.0541,  ..., -0.1657, -0.0883,  0.0923],\n",
            "        [-0.0285,  0.0314, -0.0538,  ..., -0.1370, -0.0721,  0.0830],\n",
            "        [-0.0281,  0.0312, -0.0545,  ..., -0.1499, -0.0965,  0.0828],\n",
            "        ...,\n",
            "        [-0.0286,  0.0313, -0.0539,  ..., -0.1710, -0.0873,  0.0928],\n",
            "        [-0.0304,  0.0328, -0.0560,  ..., -0.1685, -0.0141,  0.2570],\n",
            "        [-0.0285,  0.0312, -0.0541,  ..., -0.1622, -0.0854,  0.0893]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2843,  0.3122, -0.5406,  ..., -1.6571, -0.8828,  0.9229],\n",
            "        [-0.2849,  0.3144, -0.5381,  ..., -1.3703, -0.7210,  0.8296],\n",
            "        [-0.2810,  0.3125, -0.5445,  ..., -1.4995, -0.9653,  0.8278],\n",
            "        ...,\n",
            "        [-0.2862,  0.3125, -0.5395,  ..., -1.7098, -0.8730,  0.9280],\n",
            "        [-0.3040,  0.3278, -0.5604,  ..., -1.6847, -0.1412,  2.5704],\n",
            "        [-0.2850,  0.3121, -0.5412,  ..., -1.6216, -0.8535,  0.8926]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0285,  0.0313, -0.0545,  ..., -0.1737, -0.1141,  0.1002],\n",
            "        [-0.0284,  0.0311, -0.0544,  ..., -0.1866, -0.1056,  0.0989],\n",
            "        [-0.0283,  0.0313, -0.0543,  ..., -0.1316, -0.0663,  0.0841],\n",
            "        ...,\n",
            "        [-0.0284,  0.0313, -0.0538,  ..., -0.1487, -0.0793,  0.0822],\n",
            "        [-0.0282,  0.0312, -0.0548,  ..., -0.1496, -0.0828,  0.0891],\n",
            "        [-0.0287,  0.0314, -0.0542,  ..., -0.1478, -0.0488,  0.1172]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2853,  0.3127, -0.5452,  ..., -1.7370, -1.1407,  1.0023],\n",
            "        [-0.2844,  0.3111, -0.5441,  ..., -1.8657, -1.0558,  0.9888],\n",
            "        [-0.2829,  0.3127, -0.5428,  ..., -1.3163, -0.6628,  0.8410],\n",
            "        ...,\n",
            "        [-0.2842,  0.3129, -0.5381,  ..., -1.4868, -0.7928,  0.8218],\n",
            "        [-0.2818,  0.3118, -0.5484,  ..., -1.4957, -0.8279,  0.8906],\n",
            "        [-0.2872,  0.3140, -0.5419,  ..., -1.4778, -0.4877,  1.1724]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0287,  0.0312, -0.0546,  ..., -0.1684, -0.0768,  0.1097],\n",
            "        [-0.0286,  0.0313, -0.0545,  ..., -0.1484, -0.0414,  0.1251],\n",
            "        [-0.0302,  0.0327, -0.0561,  ..., -0.1917, -0.0084,  0.2947],\n",
            "        ...,\n",
            "        [-0.0285,  0.0312, -0.0546,  ..., -0.1608, -0.0862,  0.0953],\n",
            "        [-0.0284,  0.0310, -0.0539,  ..., -0.1622, -0.0845,  0.0866],\n",
            "        [-0.0291,  0.0311, -0.0544,  ..., -0.2159, -0.1021,  0.1228]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2874,  0.3118, -0.5461,  ..., -1.6842, -0.7683,  1.0967],\n",
            "        [-0.2863,  0.3126, -0.5454,  ..., -1.4842, -0.4136,  1.2506],\n",
            "        [-0.3024,  0.3274, -0.5606,  ..., -1.9167, -0.0844,  2.9474],\n",
            "        ...,\n",
            "        [-0.2852,  0.3115, -0.5457,  ..., -1.6083, -0.8624,  0.9530],\n",
            "        [-0.2842,  0.3098, -0.5389,  ..., -1.6216, -0.8446,  0.8662],\n",
            "        [-0.2913,  0.3107, -0.5443,  ..., -2.1590, -1.0206,  1.2276]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0285,  0.0311, -0.0529,  ..., -0.0895, -0.0422,  0.0529],\n",
            "        [-0.0323,  0.0334, -0.0558,  ..., -0.2676,  0.0127,  0.4244],\n",
            "        [-0.0283,  0.0309, -0.0538,  ..., -0.1427, -0.0830,  0.0745],\n",
            "        ...,\n",
            "        [-0.0287,  0.0308, -0.0538,  ..., -0.2066, -0.0982,  0.1107],\n",
            "        [-0.0288,  0.0308, -0.0540,  ..., -0.2016, -0.0960,  0.1053],\n",
            "        [-0.0285,  0.0310, -0.0538,  ..., -0.1345, -0.0482,  0.0930]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2854,  0.3110, -0.5292,  ..., -0.8945, -0.4221,  0.5290],\n",
            "        [-0.3229,  0.3339, -0.5583,  ..., -2.6756,  0.1270,  4.2438],\n",
            "        [-0.2826,  0.3092, -0.5377,  ..., -1.4269, -0.8297,  0.7446],\n",
            "        ...,\n",
            "        [-0.2873,  0.3082, -0.5384,  ..., -2.0662, -0.9815,  1.1073],\n",
            "        [-0.2876,  0.3082, -0.5401,  ..., -2.0162, -0.9601,  1.0528],\n",
            "        [-0.2845,  0.3102, -0.5382,  ..., -1.3451, -0.4817,  0.9299]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0283,  0.0310, -0.0545,  ..., -0.1394, -0.0754,  0.0833],\n",
            "        [-0.0305,  0.0327, -0.0569,  ..., -0.2114, -0.0004,  0.3457],\n",
            "        [-0.0304,  0.0326, -0.0560,  ..., -0.2002,  0.0020,  0.3118],\n",
            "        ...,\n",
            "        [-0.0302,  0.0323, -0.0556,  ..., -0.1846, -0.0161,  0.2520],\n",
            "        [-0.0287,  0.0311, -0.0538,  ..., -0.1329, -0.0316,  0.0985],\n",
            "        [-0.0298,  0.0322, -0.0558,  ..., -0.1611, -0.0222,  0.2290]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2833,  0.3103, -0.5447,  ..., -1.3939, -0.7537,  0.8332],\n",
            "        [-0.3054,  0.3274, -0.5693,  ..., -2.1141, -0.0043,  3.4566],\n",
            "        [-0.3037,  0.3260, -0.5602,  ..., -2.0017,  0.0205,  3.1181],\n",
            "        ...,\n",
            "        [-0.3024,  0.3230, -0.5563,  ..., -1.8457, -0.1611,  2.5203],\n",
            "        [-0.2867,  0.3114, -0.5380,  ..., -1.3291, -0.3155,  0.9852],\n",
            "        [-0.2977,  0.3219, -0.5583,  ..., -1.6105, -0.2221,  2.2904]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0306,  0.0325, -0.0561,  ..., -0.1999,  0.0004,  0.2858],\n",
            "        [-0.0287,  0.0312, -0.0549,  ..., -0.1544, -0.0490,  0.1142],\n",
            "        [-0.0288,  0.0309, -0.0545,  ..., -0.2095, -0.1011,  0.1071],\n",
            "        ...,\n",
            "        [-0.0288,  0.0312, -0.0546,  ..., -0.1338, -0.0368,  0.1185],\n",
            "        [-0.0286,  0.0313, -0.0536,  ..., -0.0909, -0.0432,  0.0624],\n",
            "        [-0.0287,  0.0308, -0.0545,  ..., -0.2021, -0.1001,  0.0957]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.3060,  0.3248, -0.5610,  ..., -1.9991,  0.0037,  2.8584],\n",
            "        [-0.2872,  0.3115, -0.5493,  ..., -1.5444, -0.4904,  1.1423],\n",
            "        [-0.2881,  0.3086, -0.5447,  ..., -2.0953, -1.0108,  1.0712],\n",
            "        ...,\n",
            "        [-0.2878,  0.3124, -0.5458,  ..., -1.3376, -0.3679,  1.1847],\n",
            "        [-0.2855,  0.3126, -0.5364,  ..., -0.9085, -0.4323,  0.6237],\n",
            "        [-0.2869,  0.3083, -0.5452,  ..., -2.0206, -1.0011,  0.9574]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0284,  0.0309, -0.0543,  ..., -0.1747, -0.0967,  0.0889],\n",
            "        [-0.0285,  0.0310, -0.0544,  ..., -0.1682, -0.0889,  0.0895],\n",
            "        [-0.0287,  0.0313, -0.0542,  ..., -0.1241, -0.0320,  0.1059],\n",
            "        ...,\n",
            "        [-0.0300,  0.0323, -0.0560,  ..., -0.1840, -0.0347,  0.2296],\n",
            "        [-0.0287,  0.0312, -0.0547,  ..., -0.1308, -0.0335,  0.1199],\n",
            "        [-0.0303,  0.0325, -0.0562,  ..., -0.1977, -0.0048,  0.2860]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2845,  0.3094, -0.5430,  ..., -1.7466, -0.9674,  0.8894],\n",
            "        [-0.2851,  0.3095, -0.5436,  ..., -1.6820, -0.8885,  0.8955],\n",
            "        [-0.2874,  0.3134, -0.5420,  ..., -1.2413, -0.3198,  1.0588],\n",
            "        ...,\n",
            "        [-0.2999,  0.3225, -0.5605,  ..., -1.8403, -0.3473,  2.2961],\n",
            "        [-0.2871,  0.3122, -0.5471,  ..., -1.3077, -0.3351,  1.1987],\n",
            "        [-0.3031,  0.3253, -0.5624,  ..., -1.9770, -0.0478,  2.8600]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0286,  0.0310, -0.0536,  ..., -0.1344, -0.0649,  0.0764],\n",
            "        [-0.0281,  0.0308, -0.0543,  ..., -0.1535, -0.0954,  0.0814],\n",
            "        [-0.0304,  0.0322, -0.0555,  ..., -0.2003, -0.0115,  0.2669],\n",
            "        ...,\n",
            "        [-0.0285,  0.0310, -0.0541,  ..., -0.1366, -0.0548,  0.0873],\n",
            "        [-0.0286,  0.0310, -0.0546,  ..., -0.1545, -0.0496,  0.1099],\n",
            "        [-0.0283,  0.0307, -0.0547,  ..., -0.1827, -0.1015,  0.0901]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2857,  0.3096, -0.5363,  ..., -1.3442, -0.6488,  0.7637],\n",
            "        [-0.2813,  0.3078, -0.5432,  ..., -1.5348, -0.9545,  0.8138],\n",
            "        [-0.3042,  0.3217, -0.5554,  ..., -2.0029, -0.1154,  2.6690],\n",
            "        ...,\n",
            "        [-0.2846,  0.3100, -0.5409,  ..., -1.3655, -0.5485,  0.8734],\n",
            "        [-0.2860,  0.3105, -0.5457,  ..., -1.5448, -0.4962,  1.0993],\n",
            "        [-0.2833,  0.3065, -0.5470,  ..., -1.8274, -1.0146,  0.9011]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0287,  0.0306, -0.0541,  ..., -0.2035, -0.1031,  0.1052],\n",
            "        [-0.0285,  0.0308, -0.0544,  ..., -0.1702, -0.0819,  0.1035],\n",
            "        [-0.0285,  0.0309, -0.0538,  ..., -0.1195, -0.0354,  0.0969],\n",
            "        ...,\n",
            "        [-0.0288,  0.0310, -0.0538,  ..., -0.1269, -0.0276,  0.1144],\n",
            "        [-0.0286,  0.0309, -0.0546,  ..., -0.1559, -0.0526,  0.1209],\n",
            "        [-0.0286,  0.0308, -0.0540,  ..., -0.1535, -0.0534,  0.1128]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2865,  0.3056, -0.5411,  ..., -2.0345, -1.0306,  1.0521],\n",
            "        [-0.2849,  0.3076, -0.5443,  ..., -1.7019, -0.8189,  1.0350],\n",
            "        [-0.2849,  0.3094, -0.5383,  ..., -1.1951, -0.3544,  0.9690],\n",
            "        ...,\n",
            "        [-0.2875,  0.3097, -0.5383,  ..., -1.2695, -0.2757,  1.1441],\n",
            "        [-0.2862,  0.3088, -0.5458,  ..., -1.5587, -0.5260,  1.2092],\n",
            "        [-0.2859,  0.3084, -0.5399,  ..., -1.5353, -0.5335,  1.1277]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0298,  0.0318, -0.0555,  ..., -0.1844, -0.0173,  0.2549],\n",
            "        [-0.0284,  0.0304, -0.0545,  ..., -0.1889, -0.0941,  0.1036],\n",
            "        [-0.0299,  0.0318, -0.0553,  ..., -0.1837, -0.0228,  0.2512],\n",
            "        ...,\n",
            "        [-0.0284,  0.0303, -0.0542,  ..., -0.1967, -0.1086,  0.0948],\n",
            "        [-0.0284,  0.0306, -0.0539,  ..., -0.1658, -0.0892,  0.0890],\n",
            "        [-0.0300,  0.0321, -0.0560,  ..., -0.1953, -0.0028,  0.3066]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2981,  0.3176, -0.5545,  ..., -1.8440, -0.1733,  2.5485],\n",
            "        [-0.2845,  0.3045, -0.5450,  ..., -1.8888, -0.9414,  1.0357],\n",
            "        [-0.2988,  0.3180, -0.5532,  ..., -1.8370, -0.2281,  2.5125],\n",
            "        ...,\n",
            "        [-0.2839,  0.3033, -0.5416,  ..., -1.9668, -1.0861,  0.9477],\n",
            "        [-0.2844,  0.3056, -0.5387,  ..., -1.6576, -0.8916,  0.8896],\n",
            "        [-0.2995,  0.3213, -0.5596,  ..., -1.9527, -0.0279,  3.0657]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0284,  0.0307, -0.0534,  ..., -0.1320, -0.0667,  0.0759],\n",
            "        [-0.0285,  0.0308, -0.0534,  ..., -0.1184, -0.0431,  0.0819],\n",
            "        [-0.0303,  0.0319, -0.0556,  ..., -0.2119, -0.0073,  0.2970],\n",
            "        ...,\n",
            "        [-0.0283,  0.0304, -0.0542,  ..., -0.1848, -0.0995,  0.0973],\n",
            "        [-0.0287,  0.0305, -0.0539,  ..., -0.2076, -0.1006,  0.1085],\n",
            "        [-0.0285,  0.0306, -0.0538,  ..., -0.1592, -0.0763,  0.0886]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2838,  0.3073, -0.5340,  ..., -1.3203, -0.6673,  0.7586],\n",
            "        [-0.2851,  0.3084, -0.5340,  ..., -1.1835, -0.4311,  0.8189],\n",
            "        [-0.3032,  0.3192, -0.5562,  ..., -2.1192, -0.0734,  2.9703],\n",
            "        ...,\n",
            "        [-0.2833,  0.3043, -0.5416,  ..., -1.8482, -0.9951,  0.9732],\n",
            "        [-0.2871,  0.3047, -0.5386,  ..., -2.0764, -1.0064,  1.0846],\n",
            "        [-0.2851,  0.3060, -0.5380,  ..., -1.5916, -0.7628,  0.8856]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0286,  0.0307, -0.0544,  ..., -0.1742, -0.0736,  0.1102],\n",
            "        [-0.0302,  0.0322, -0.0565,  ..., -0.1930, -0.0091,  0.2974],\n",
            "        [-0.0302,  0.0320, -0.0562,  ..., -0.1979, -0.0067,  0.2911],\n",
            "        ...,\n",
            "        [-0.0295,  0.0320, -0.0560,  ..., -0.1778, -0.0209,  0.2442],\n",
            "        [-0.0284,  0.0309, -0.0534,  ..., -0.0909, -0.0507,  0.0502],\n",
            "        [-0.0284,  0.0309, -0.0538,  ..., -0.1286, -0.0686,  0.0779]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2861,  0.3073, -0.5441,  ..., -1.7419, -0.7362,  1.1023],\n",
            "        [-0.3017,  0.3221, -0.5647,  ..., -1.9301, -0.0909,  2.9742],\n",
            "        [-0.3019,  0.3202, -0.5624,  ..., -1.9791, -0.0673,  2.9108],\n",
            "        ...,\n",
            "        [-0.2950,  0.3199, -0.5605,  ..., -1.7778, -0.2086,  2.4422],\n",
            "        [-0.2842,  0.3095, -0.5337,  ..., -0.9094, -0.5066,  0.5023],\n",
            "        [-0.2842,  0.3089, -0.5384,  ..., -1.2857, -0.6858,  0.7792]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0286,  0.0307, -0.0545,  ..., -0.1838, -0.0957,  0.1041],\n",
            "        [-0.0284,  0.0308, -0.0545,  ..., -0.1660, -0.0995,  0.0849],\n",
            "        [-0.0286,  0.0310, -0.0538,  ..., -0.0961, -0.0369,  0.0722],\n",
            "        ...,\n",
            "        [-0.0286,  0.0311, -0.0541,  ..., -0.1145, -0.0352,  0.0924],\n",
            "        [-0.0282,  0.0308, -0.0547,  ..., -0.1492, -0.0951,  0.0804],\n",
            "        [-0.0302,  0.0321, -0.0564,  ..., -0.1850, -0.0105,  0.2828]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2858,  0.3075, -0.5454,  ..., -1.8384, -0.9567,  1.0413],\n",
            "        [-0.2836,  0.3076, -0.5447,  ..., -1.6603, -0.9950,  0.8490],\n",
            "        [-0.2863,  0.3104, -0.5379,  ..., -0.9609, -0.3689,  0.7221],\n",
            "        ...,\n",
            "        [-0.2860,  0.3108, -0.5413,  ..., -1.1446, -0.3522,  0.9237],\n",
            "        [-0.2820,  0.3077, -0.5466,  ..., -1.4915, -0.9508,  0.8045],\n",
            "        [-0.3015,  0.3214, -0.5638,  ..., -1.8500, -0.1049,  2.8279]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0300,  0.0320, -0.0562,  ..., -0.1750, -0.0108,  0.2621],\n",
            "        [-0.0286,  0.0309, -0.0538,  ..., -0.1155, -0.0561,  0.0667],\n",
            "        [-0.0294,  0.0319, -0.0562,  ..., -0.1490, -0.0253,  0.2160],\n",
            "        ...,\n",
            "        [-0.0299,  0.0322, -0.0565,  ..., -0.1884, -0.0055,  0.2913],\n",
            "        [-0.0285,  0.0310, -0.0539,  ..., -0.0994, -0.0388,  0.0748],\n",
            "        [-0.0284,  0.0308, -0.0543,  ..., -0.1464, -0.0669,  0.0910]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2998,  0.3201, -0.5618,  ..., -1.7496, -0.1076,  2.6212],\n",
            "        [-0.2856,  0.3089, -0.5379,  ..., -1.1545, -0.5611,  0.6666],\n",
            "        [-0.2939,  0.3186, -0.5624,  ..., -1.4897, -0.2527,  2.1598],\n",
            "        ...,\n",
            "        [-0.2988,  0.3218, -0.5649,  ..., -1.8836, -0.0550,  2.9128],\n",
            "        [-0.2846,  0.3104, -0.5393,  ..., -0.9944, -0.3876,  0.7482],\n",
            "        [-0.2837,  0.3084, -0.5429,  ..., -1.4644, -0.6686,  0.9097]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0285,  0.0306, -0.0541,  ..., -0.1695, -0.0785,  0.0969],\n",
            "        [-0.0282,  0.0306, -0.0542,  ..., -0.1634, -0.0992,  0.0844],\n",
            "        [-0.0285,  0.0305, -0.0540,  ..., -0.1918, -0.0937,  0.1030],\n",
            "        ...,\n",
            "        [-0.0285,  0.0306, -0.0545,  ..., -0.1958, -0.0989,  0.1128],\n",
            "        [-0.0299,  0.0318, -0.0558,  ..., -0.1883, -0.0199,  0.2676],\n",
            "        [-0.0296,  0.0318, -0.0557,  ..., -0.1674, -0.0245,  0.2419]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2847,  0.3059, -0.5411,  ..., -1.6954, -0.7853,  0.9691],\n",
            "        [-0.2824,  0.3057, -0.5417,  ..., -1.6338, -0.9920,  0.8437],\n",
            "        [-0.2853,  0.3050, -0.5402,  ..., -1.9185, -0.9367,  1.0299],\n",
            "        ...,\n",
            "        [-0.2851,  0.3055, -0.5452,  ..., -1.9585, -0.9890,  1.1275],\n",
            "        [-0.2989,  0.3178, -0.5578,  ..., -1.8827, -0.1987,  2.6763],\n",
            "        [-0.2962,  0.3176, -0.5571,  ..., -1.6742, -0.2448,  2.4190]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0285,  0.0307, -0.0527,  ..., -0.0866, -0.0454,  0.0485],\n",
            "        [-0.0283,  0.0304, -0.0535,  ..., -0.1616, -0.0879,  0.0878],\n",
            "        [-0.0284,  0.0305, -0.0532,  ..., -0.1429, -0.0702,  0.0808],\n",
            "        ...,\n",
            "        [-0.0283,  0.0304, -0.0540,  ..., -0.1695, -0.0858,  0.1004],\n",
            "        [-0.0284,  0.0304, -0.0534,  ..., -0.1703, -0.0907,  0.0971],\n",
            "        [-0.0283,  0.0304, -0.0536,  ..., -0.1567, -0.0788,  0.0824]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2849,  0.3066, -0.5275,  ..., -0.8660, -0.4538,  0.4851],\n",
            "        [-0.2828,  0.3042, -0.5351,  ..., -1.6161, -0.8785,  0.8783],\n",
            "        [-0.2836,  0.3055, -0.5323,  ..., -1.4292, -0.7022,  0.8079],\n",
            "        ...,\n",
            "        [-0.2834,  0.3036, -0.5397,  ..., -1.6951, -0.8579,  1.0039],\n",
            "        [-0.2837,  0.3041, -0.5342,  ..., -1.7032, -0.9073,  0.9707],\n",
            "        [-0.2830,  0.3040, -0.5362,  ..., -1.5666, -0.7882,  0.8240]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-2.8452e-02,  3.0618e-02, -5.2965e-02,  ..., -1.1298e-01,\n",
            "         -5.0213e-02,  7.5722e-02],\n",
            "        [-2.8044e-02,  3.0501e-02, -5.3789e-02,  ..., -1.3410e-01,\n",
            "         -6.7263e-02,  8.5389e-02],\n",
            "        [-2.9411e-02,  3.1638e-02, -5.6073e-02,  ..., -1.8144e-01,\n",
            "         -7.6184e-03,  2.7962e-01],\n",
            "        ...,\n",
            "        [-2.8155e-02,  3.0405e-02, -5.3229e-02,  ..., -1.3646e-01,\n",
            "         -7.6240e-02,  7.5699e-02],\n",
            "        [-2.9416e-02,  3.1651e-02, -5.5600e-02,  ..., -1.8762e-01,\n",
            "         -2.8365e-04,  2.9486e-01],\n",
            "        [-2.9332e-02,  3.1516e-02, -5.5832e-02,  ..., -1.9084e-01,\n",
            "         -1.4098e-03,  2.8422e-01]], grad_fn=<CatBackward0>)\n",
            "New tensor([[-2.8452e-01,  3.0618e-01, -5.2965e-01,  ..., -1.1298e+00,\n",
            "         -5.0213e-01,  7.5722e-01],\n",
            "        [-2.8044e-01,  3.0501e-01, -5.3789e-01,  ..., -1.3410e+00,\n",
            "         -6.7263e-01,  8.5389e-01],\n",
            "        [-2.9411e-01,  3.1638e-01, -5.6073e-01,  ..., -1.8144e+00,\n",
            "         -7.6184e-02,  2.7962e+00],\n",
            "        ...,\n",
            "        [-2.8155e-01,  3.0405e-01, -5.3229e-01,  ..., -1.3646e+00,\n",
            "         -7.6240e-01,  7.5699e-01],\n",
            "        [-2.9416e-01,  3.1651e-01, -5.5600e-01,  ..., -1.8762e+00,\n",
            "         -2.8365e-03,  2.9486e+00],\n",
            "        [-2.9332e-01,  3.1516e-01, -5.5832e-01,  ..., -1.9084e+00,\n",
            "         -1.4098e-02,  2.8422e+00]], grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0281,  0.0305, -0.0541,  ..., -0.1362, -0.0692,  0.0814],\n",
            "        [-0.0283,  0.0304, -0.0537,  ..., -0.1740, -0.0866,  0.0855],\n",
            "        [-0.0281,  0.0307, -0.0543,  ..., -0.1459, -0.0482,  0.1174],\n",
            "        ...,\n",
            "        [-0.0291,  0.0317, -0.0560,  ..., -0.1687, -0.0111,  0.2628],\n",
            "        [-0.0282,  0.0305, -0.0539,  ..., -0.1577, -0.0887,  0.0859],\n",
            "        [-0.0285,  0.0306, -0.0543,  ..., -0.1792, -0.0685,  0.1181]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2809,  0.3052, -0.5408,  ..., -1.3619, -0.6922,  0.8137],\n",
            "        [-0.2831,  0.3035, -0.5365,  ..., -1.7396, -0.8665,  0.8554],\n",
            "        [-0.2813,  0.3069, -0.5429,  ..., -1.4587, -0.4822,  1.1744],\n",
            "        ...,\n",
            "        [-0.2910,  0.3172, -0.5604,  ..., -1.6866, -0.1105,  2.6285],\n",
            "        [-0.2816,  0.3047, -0.5390,  ..., -1.5770, -0.8870,  0.8588],\n",
            "        [-0.2845,  0.3057, -0.5431,  ..., -1.7918, -0.6850,  1.1812]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0283,  0.0307, -0.0539,  ..., -0.1355, -0.0741,  0.0771],\n",
            "        [-0.0282,  0.0305, -0.0542,  ..., -0.1497, -0.0848,  0.0804],\n",
            "        [-0.0285,  0.0309, -0.0533,  ..., -0.0778, -0.0436,  0.0465],\n",
            "        ...,\n",
            "        [-0.0294,  0.0317, -0.0560,  ..., -0.1757, -0.0356,  0.2443],\n",
            "        [-0.0291,  0.0317, -0.0561,  ..., -0.1394, -0.0266,  0.2019],\n",
            "        [-0.0281,  0.0305, -0.0542,  ..., -0.1465, -0.0843,  0.0792]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2829,  0.3072, -0.5388,  ..., -1.3553, -0.7412,  0.7710],\n",
            "        [-0.2818,  0.3052, -0.5417,  ..., -1.4974, -0.8478,  0.8042],\n",
            "        [-0.2847,  0.3090, -0.5329,  ..., -0.7779, -0.4362,  0.4645],\n",
            "        ...,\n",
            "        [-0.2941,  0.3168, -0.5602,  ..., -1.7573, -0.3559,  2.4428],\n",
            "        [-0.2907,  0.3167, -0.5606,  ..., -1.3938, -0.2661,  2.0190],\n",
            "        [-0.2811,  0.3053, -0.5416,  ..., -1.4650, -0.8431,  0.7924]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0286,  0.0309, -0.0539,  ..., -0.1320, -0.0461,  0.0932],\n",
            "        [-0.0282,  0.0307, -0.0543,  ..., -0.1420, -0.0813,  0.0833],\n",
            "        [-0.0284,  0.0310, -0.0535,  ..., -0.0834, -0.0463,  0.0426],\n",
            "        ...,\n",
            "        [-0.0283,  0.0306, -0.0548,  ..., -0.1790, -0.0949,  0.0995],\n",
            "        [-0.0284,  0.0307, -0.0539,  ..., -0.1646, -0.0836,  0.0931],\n",
            "        [-0.0280,  0.0307, -0.0544,  ..., -0.1470, -0.0914,  0.0792]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2860,  0.3093, -0.5392,  ..., -1.3196, -0.4610,  0.9317],\n",
            "        [-0.2818,  0.3072, -0.5426,  ..., -1.4200, -0.8130,  0.8334],\n",
            "        [-0.2843,  0.3097, -0.5345,  ..., -0.8338, -0.4634,  0.4255],\n",
            "        ...,\n",
            "        [-0.2832,  0.3059, -0.5477,  ..., -1.7896, -0.9494,  0.9950],\n",
            "        [-0.2843,  0.3074, -0.5391,  ..., -1.6457, -0.8363,  0.9314],\n",
            "        [-0.2801,  0.3067, -0.5444,  ..., -1.4700, -0.9138,  0.7923]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0284,  0.0308, -0.0541,  ..., -0.1469, -0.0566,  0.1048],\n",
            "        [-0.0284,  0.0305, -0.0538,  ..., -0.1791, -0.0911,  0.0958],\n",
            "        [-0.0280,  0.0306, -0.0539,  ..., -0.1407, -0.0863,  0.0801],\n",
            "        ...,\n",
            "        [-0.0293,  0.0317, -0.0557,  ..., -0.1595, -0.0252,  0.2230],\n",
            "        [-0.0283,  0.0307, -0.0535,  ..., -0.1319, -0.0712,  0.0716],\n",
            "        [-0.0285,  0.0307, -0.0532,  ..., -0.1342, -0.0673,  0.0716]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2841,  0.3078, -0.5405,  ..., -1.4691, -0.5664,  1.0479],\n",
            "        [-0.2837,  0.3049, -0.5379,  ..., -1.7907, -0.9110,  0.9580],\n",
            "        [-0.2801,  0.3055, -0.5395,  ..., -1.4071, -0.8631,  0.8008],\n",
            "        ...,\n",
            "        [-0.2926,  0.3166, -0.5574,  ..., -1.5954, -0.2517,  2.2305],\n",
            "        [-0.2830,  0.3074, -0.5353,  ..., -1.3187, -0.7119,  0.7164],\n",
            "        [-0.2848,  0.3068, -0.5324,  ..., -1.3420, -0.6732,  0.7164]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0281,  0.0303, -0.0538,  ..., -0.1724, -0.1032,  0.0916],\n",
            "        [-0.0283,  0.0307, -0.0528,  ..., -0.0789, -0.0512,  0.0460],\n",
            "        [-0.0278,  0.0304, -0.0540,  ..., -0.1418, -0.0990,  0.0754],\n",
            "        ...,\n",
            "        [-0.0282,  0.0305, -0.0538,  ..., -0.1608, -0.0687,  0.1063],\n",
            "        [-0.0281,  0.0305, -0.0532,  ..., -0.1150, -0.0716,  0.0644],\n",
            "        [-0.0283,  0.0307, -0.0537,  ..., -0.1193, -0.0330,  0.1113]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2807,  0.3029, -0.5381,  ..., -1.7243, -1.0316,  0.9156],\n",
            "        [-0.2827,  0.3074, -0.5277,  ..., -0.7887, -0.5119,  0.4602],\n",
            "        [-0.2782,  0.3041, -0.5398,  ..., -1.4182, -0.9905,  0.7538],\n",
            "        ...,\n",
            "        [-0.2824,  0.3050, -0.5385,  ..., -1.6080, -0.6870,  1.0635],\n",
            "        [-0.2810,  0.3053, -0.5318,  ..., -1.1501, -0.7160,  0.6441],\n",
            "        [-0.2831,  0.3070, -0.5366,  ..., -1.1933, -0.3304,  1.1132]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0281,  0.0306, -0.0529,  ..., -0.1062, -0.0372,  0.0824],\n",
            "        [-0.0282,  0.0301, -0.0531,  ..., -0.1756, -0.0913,  0.0921],\n",
            "        [-0.0282,  0.0304, -0.0527,  ..., -0.1177, -0.0667,  0.0612],\n",
            "        ...,\n",
            "        [-0.0287,  0.0313, -0.0548,  ..., -0.1601, -0.0062,  0.2434],\n",
            "        [-0.0281,  0.0305, -0.0524,  ..., -0.0932, -0.0588,  0.0523],\n",
            "        [-0.0280,  0.0303, -0.0528,  ..., -0.1246, -0.0759,  0.0571]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2809,  0.3058, -0.5294,  ..., -1.0621, -0.3718,  0.8240],\n",
            "        [-0.2817,  0.3013, -0.5306,  ..., -1.7563, -0.9131,  0.9212],\n",
            "        [-0.2815,  0.3037, -0.5272,  ..., -1.1765, -0.6671,  0.6117],\n",
            "        ...,\n",
            "        [-0.2872,  0.3133, -0.5479,  ..., -1.6009, -0.0623,  2.4343],\n",
            "        [-0.2814,  0.3054, -0.5237,  ..., -0.9323, -0.5882,  0.5230],\n",
            "        [-0.2796,  0.3027, -0.5284,  ..., -1.2456, -0.7585,  0.5713]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0280,  0.0302, -0.0533,  ..., -0.1454, -0.0757,  0.0888],\n",
            "        [-0.0279,  0.0301, -0.0528,  ..., -0.1434, -0.0841,  0.0761],\n",
            "        [-0.0280,  0.0301, -0.0528,  ..., -0.1444, -0.0784,  0.0754],\n",
            "        ...,\n",
            "        [-0.0279,  0.0302, -0.0530,  ..., -0.1272, -0.0781,  0.0759],\n",
            "        [-0.0279,  0.0302, -0.0528,  ..., -0.1418, -0.0849,  0.0799],\n",
            "        [-0.0280,  0.0302, -0.0527,  ..., -0.1528, -0.0882,  0.0884]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2796,  0.3016, -0.5327,  ..., -1.4538, -0.7570,  0.8882],\n",
            "        [-0.2795,  0.3013, -0.5283,  ..., -1.4345, -0.8413,  0.7605],\n",
            "        [-0.2801,  0.3014, -0.5283,  ..., -1.4436, -0.7838,  0.7537],\n",
            "        ...,\n",
            "        [-0.2789,  0.3018, -0.5296,  ..., -1.2724, -0.7812,  0.7590],\n",
            "        [-0.2793,  0.3015, -0.5283,  ..., -1.4177, -0.8492,  0.7989],\n",
            "        [-0.2798,  0.3024, -0.5274,  ..., -1.5280, -0.8823,  0.8840]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0282,  0.0306, -0.0526,  ..., -0.0787, -0.0490,  0.0437],\n",
            "        [-0.0280,  0.0301, -0.0532,  ..., -0.1555, -0.0865,  0.0830],\n",
            "        [-0.0279,  0.0303, -0.0529,  ..., -0.1280, -0.0778,  0.0635],\n",
            "        ...,\n",
            "        [-0.0286,  0.0311, -0.0548,  ..., -0.1351, -0.0379,  0.1936],\n",
            "        [-0.0279,  0.0303, -0.0537,  ..., -0.1472, -0.0724,  0.1072],\n",
            "        [-0.0282,  0.0304, -0.0527,  ..., -0.1080, -0.0630,  0.0573]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2815,  0.3057, -0.5259,  ..., -0.7872, -0.4902,  0.4365],\n",
            "        [-0.2798,  0.3011, -0.5324,  ..., -1.5553, -0.8647,  0.8296],\n",
            "        [-0.2794,  0.3029, -0.5288,  ..., -1.2797, -0.7778,  0.6352],\n",
            "        ...,\n",
            "        [-0.2864,  0.3110, -0.5481,  ..., -1.3509, -0.3790,  1.9356],\n",
            "        [-0.2789,  0.3027, -0.5375,  ..., -1.4723, -0.7238,  1.0725],\n",
            "        [-0.2817,  0.3038, -0.5266,  ..., -1.0797, -0.6304,  0.5733]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0288,  0.0313, -0.0551,  ..., -0.1401, -0.0305,  0.2018],\n",
            "        [-0.0277,  0.0302, -0.0541,  ..., -0.1537, -0.1051,  0.0822],\n",
            "        [-0.0285,  0.0314, -0.0557,  ..., -0.1341, -0.0342,  0.1909],\n",
            "        ...,\n",
            "        [-0.0286,  0.0314, -0.0552,  ..., -0.1392, -0.0150,  0.2164],\n",
            "        [-0.0285,  0.0312, -0.0555,  ..., -0.1474, -0.0462,  0.1914],\n",
            "        [-0.0281,  0.0307, -0.0535,  ..., -0.1042, -0.0473,  0.0765]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2882,  0.3134, -0.5511,  ..., -1.4010, -0.3050,  2.0177],\n",
            "        [-0.2767,  0.3024, -0.5405,  ..., -1.5374, -1.0514,  0.8219],\n",
            "        [-0.2853,  0.3140, -0.5572,  ..., -1.3412, -0.3416,  1.9090],\n",
            "        ...,\n",
            "        [-0.2859,  0.3135, -0.5525,  ..., -1.3918, -0.1495,  2.1637],\n",
            "        [-0.2846,  0.3120, -0.5550,  ..., -1.4735, -0.4621,  1.9137],\n",
            "        [-0.2809,  0.3069, -0.5352,  ..., -1.0416, -0.4725,  0.7647]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0279,  0.0302, -0.0540,  ..., -0.1625, -0.0920,  0.0769],\n",
            "        [-0.0279,  0.0304, -0.0540,  ..., -0.1399, -0.0758,  0.0838],\n",
            "        [-0.0279,  0.0304, -0.0539,  ..., -0.1268, -0.0785,  0.0674],\n",
            "        ...,\n",
            "        [-0.0280,  0.0302, -0.0540,  ..., -0.1909, -0.1051,  0.0972],\n",
            "        [-0.0282,  0.0307, -0.0532,  ..., -0.0918, -0.0647,  0.0521],\n",
            "        [-0.0279,  0.0306, -0.0538,  ..., -0.1160, -0.0825,  0.0719]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2792,  0.3021, -0.5404,  ..., -1.6254, -0.9202,  0.7688],\n",
            "        [-0.2791,  0.3044, -0.5401,  ..., -1.3993, -0.7584,  0.8383],\n",
            "        [-0.2792,  0.3044, -0.5392,  ..., -1.2682, -0.7849,  0.6741],\n",
            "        ...,\n",
            "        [-0.2801,  0.3016, -0.5404,  ..., -1.9093, -1.0511,  0.9722],\n",
            "        [-0.2820,  0.3075, -0.5320,  ..., -0.9182, -0.6472,  0.5215],\n",
            "        [-0.2787,  0.3063, -0.5380,  ..., -1.1600, -0.8249,  0.7189]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0285,  0.0313, -0.0560,  ..., -0.1345, -0.0252,  0.1992],\n",
            "        [-0.0278,  0.0304, -0.0536,  ..., -0.1008, -0.0684,  0.0532],\n",
            "        [-0.0278,  0.0305, -0.0545,  ..., -0.1304, -0.0527,  0.1028],\n",
            "        ...,\n",
            "        [-0.0276,  0.0303, -0.0540,  ..., -0.1263, -0.0864,  0.0639],\n",
            "        [-0.0281,  0.0304, -0.0536,  ..., -0.1265, -0.0734,  0.0697],\n",
            "        [-0.0281,  0.0307, -0.0535,  ..., -0.0878, -0.0501,  0.0587]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2849,  0.3130, -0.5599,  ..., -1.3449, -0.2518,  1.9925],\n",
            "        [-0.2780,  0.3044, -0.5364,  ..., -1.0077, -0.6843,  0.5324],\n",
            "        [-0.2785,  0.3053, -0.5450,  ..., -1.3040, -0.5272,  1.0276],\n",
            "        ...,\n",
            "        [-0.2764,  0.3029, -0.5403,  ..., -1.2632, -0.8644,  0.6389],\n",
            "        [-0.2809,  0.3039, -0.5359,  ..., -1.2653, -0.7342,  0.6970],\n",
            "        [-0.2811,  0.3068, -0.5350,  ..., -0.8779, -0.5010,  0.5874]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0280,  0.0305, -0.0537,  ..., -0.1007, -0.0460,  0.0821],\n",
            "        [-0.0281,  0.0304, -0.0535,  ..., -0.1193, -0.0600,  0.0842],\n",
            "        [-0.0277,  0.0302, -0.0534,  ..., -0.1130, -0.0767,  0.0516],\n",
            "        ...,\n",
            "        [-0.0276,  0.0302, -0.0542,  ..., -0.1532, -0.0946,  0.0882],\n",
            "        [-0.0278,  0.0304, -0.0534,  ..., -0.0881, -0.0617,  0.0488],\n",
            "        [-0.0276,  0.0299, -0.0539,  ..., -0.1615, -0.0989,  0.0714]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2797,  0.3049, -0.5369,  ..., -1.0071, -0.4602,  0.8215],\n",
            "        [-0.2808,  0.3037, -0.5346,  ..., -1.1929, -0.6003,  0.8418],\n",
            "        [-0.2771,  0.3019, -0.5338,  ..., -1.1304, -0.7674,  0.5158],\n",
            "        ...,\n",
            "        [-0.2757,  0.3015, -0.5423,  ..., -1.5323, -0.9462,  0.8824],\n",
            "        [-0.2781,  0.3036, -0.5336,  ..., -0.8810, -0.6169,  0.4880],\n",
            "        [-0.2760,  0.2995, -0.5387,  ..., -1.6147, -0.9885,  0.7137]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0276,  0.0299, -0.0533,  ..., -0.1603, -0.0929,  0.0837],\n",
            "        [-0.0275,  0.0302, -0.0538,  ..., -0.1231, -0.0617,  0.0898],\n",
            "        [-0.0273,  0.0299, -0.0536,  ..., -0.1265, -0.0862,  0.0629],\n",
            "        ...,\n",
            "        [-0.0281,  0.0311, -0.0556,  ..., -0.1382, -0.0240,  0.2196],\n",
            "        [-0.0275,  0.0302, -0.0533,  ..., -0.0959, -0.0767,  0.0520],\n",
            "        [-0.0275,  0.0301, -0.0536,  ..., -0.1235, -0.0823,  0.0633]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2755,  0.2988, -0.5330,  ..., -1.6026, -0.9286,  0.8372],\n",
            "        [-0.2755,  0.3017, -0.5384,  ..., -1.2310, -0.6166,  0.8978],\n",
            "        [-0.2734,  0.2991, -0.5360,  ..., -1.2651, -0.8620,  0.6294],\n",
            "        ...,\n",
            "        [-0.2809,  0.3105, -0.5560,  ..., -1.3819, -0.2401,  2.1962],\n",
            "        [-0.2753,  0.3019, -0.5332,  ..., -0.9585, -0.7665,  0.5201],\n",
            "        [-0.2747,  0.3007, -0.5363,  ..., -1.2355, -0.8233,  0.6329]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0274,  0.0300, -0.0533,  ..., -0.1143, -0.0764,  0.0662],\n",
            "        [-0.0270,  0.0297, -0.0536,  ..., -0.1458, -0.1004,  0.0739],\n",
            "        [-0.0273,  0.0299, -0.0532,  ..., -0.1310, -0.0864,  0.0671],\n",
            "        ...,\n",
            "        [-0.0276,  0.0309, -0.0558,  ..., -0.1296, -0.0179,  0.2234],\n",
            "        [-0.0278,  0.0309, -0.0556,  ..., -0.1319, -0.0326,  0.2075],\n",
            "        [-0.0274,  0.0299, -0.0533,  ..., -0.1172, -0.0763,  0.0569]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2743,  0.3001, -0.5331,  ..., -1.1429, -0.7637,  0.6621],\n",
            "        [-0.2704,  0.2967, -0.5363,  ..., -1.4580, -1.0041,  0.7388],\n",
            "        [-0.2735,  0.2987, -0.5323,  ..., -1.3095, -0.8643,  0.6708],\n",
            "        ...,\n",
            "        [-0.2760,  0.3095, -0.5580,  ..., -1.2960, -0.1787,  2.2342],\n",
            "        [-0.2778,  0.3085, -0.5557,  ..., -1.3193, -0.3258,  2.0748],\n",
            "        [-0.2743,  0.2988, -0.5325,  ..., -1.1717, -0.7633,  0.5692]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0272,  0.0297, -0.0532,  ..., -0.1211, -0.0823,  0.0583],\n",
            "        [-0.0272,  0.0298, -0.0535,  ..., -0.1252, -0.0817,  0.0723],\n",
            "        [-0.0275,  0.0309, -0.0553,  ..., -0.1165, -0.0259,  0.1962],\n",
            "        ...,\n",
            "        [-0.0269,  0.0297, -0.0539,  ..., -0.1396, -0.1092,  0.0698],\n",
            "        [-0.0276,  0.0305, -0.0554,  ..., -0.1216, -0.0482,  0.1804],\n",
            "        [-0.0275,  0.0297, -0.0530,  ..., -0.1353, -0.0834,  0.0603]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2719,  0.2974, -0.5323,  ..., -1.2114, -0.8230,  0.5829],\n",
            "        [-0.2718,  0.2983, -0.5352,  ..., -1.2518, -0.8173,  0.7231],\n",
            "        [-0.2749,  0.3085, -0.5533,  ..., -1.1651, -0.2588,  1.9625],\n",
            "        ...,\n",
            "        [-0.2689,  0.2968, -0.5387,  ..., -1.3959, -1.0916,  0.6983],\n",
            "        [-0.2756,  0.3054, -0.5542,  ..., -1.2161, -0.4824,  1.8039],\n",
            "        [-0.2746,  0.2970, -0.5297,  ..., -1.3527, -0.8342,  0.6032]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0273,  0.0305, -0.0549,  ..., -0.1253, -0.0548,  0.1609],\n",
            "        [-0.0275,  0.0307, -0.0550,  ..., -0.1201, -0.0331,  0.1851],\n",
            "        [-0.0273,  0.0298, -0.0527,  ..., -0.1260, -0.0871,  0.0535],\n",
            "        ...,\n",
            "        [-0.0274,  0.0298, -0.0529,  ..., -0.1248, -0.0723,  0.0660],\n",
            "        [-0.0273,  0.0297, -0.0529,  ..., -0.1373, -0.0906,  0.0663],\n",
            "        [-0.0272,  0.0297, -0.0532,  ..., -0.1258, -0.0936,  0.0574]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2732,  0.3046, -0.5490,  ..., -1.2527, -0.5484,  1.6088],\n",
            "        [-0.2754,  0.3066, -0.5501,  ..., -1.2008, -0.3309,  1.8506],\n",
            "        [-0.2735,  0.2981, -0.5267,  ..., -1.2602, -0.8711,  0.5347],\n",
            "        ...,\n",
            "        [-0.2741,  0.2984, -0.5290,  ..., -1.2478, -0.7230,  0.6602],\n",
            "        [-0.2728,  0.2966, -0.5288,  ..., -1.3734, -0.9065,  0.6626],\n",
            "        [-0.2717,  0.2970, -0.5317,  ..., -1.2577, -0.9361,  0.5744]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0269,  0.0298, -0.0536,  ..., -0.1033, -0.0745,  0.0679],\n",
            "        [-0.0270,  0.0297, -0.0533,  ..., -0.1231, -0.0944,  0.0637],\n",
            "        [-0.0270,  0.0297, -0.0533,  ..., -0.1194, -0.0985,  0.0608],\n",
            "        ...,\n",
            "        [-0.0271,  0.0295, -0.0532,  ..., -0.1549, -0.0985,  0.0715],\n",
            "        [-0.0269,  0.0294, -0.0534,  ..., -0.1670, -0.1071,  0.0820],\n",
            "        [-0.0273,  0.0299, -0.0529,  ..., -0.0908, -0.0681,  0.0485]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2687,  0.2981, -0.5362,  ..., -1.0334, -0.7452,  0.6789],\n",
            "        [-0.2696,  0.2965, -0.5334,  ..., -1.2311, -0.9443,  0.6367],\n",
            "        [-0.2699,  0.2973, -0.5326,  ..., -1.1944, -0.9853,  0.6075],\n",
            "        ...,\n",
            "        [-0.2707,  0.2947, -0.5323,  ..., -1.5491, -0.9853,  0.7149],\n",
            "        [-0.2690,  0.2936, -0.5338,  ..., -1.6702, -1.0712,  0.8203],\n",
            "        [-0.2731,  0.2988, -0.5291,  ..., -0.9082, -0.6813,  0.4851]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0272,  0.0297, -0.0529,  ..., -0.1406, -0.0901,  0.0628],\n",
            "        [-0.0273,  0.0297, -0.0528,  ..., -0.1305, -0.0870,  0.0635],\n",
            "        [-0.0272,  0.0307, -0.0552,  ..., -0.1158, -0.0134,  0.2018],\n",
            "        ...,\n",
            "        [-0.0276,  0.0300, -0.0534,  ..., -0.1088, -0.0405,  0.0980],\n",
            "        [-0.0271,  0.0295, -0.0531,  ..., -0.1547, -0.0958,  0.0711],\n",
            "        [-0.0272,  0.0297, -0.0530,  ..., -0.1203, -0.0819,  0.0647]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2724,  0.2967, -0.5289,  ..., -1.4057, -0.9013,  0.6281],\n",
            "        [-0.2728,  0.2967, -0.5284,  ..., -1.3047, -0.8696,  0.6351],\n",
            "        [-0.2722,  0.3073, -0.5520,  ..., -1.1580, -0.1337,  2.0181],\n",
            "        ...,\n",
            "        [-0.2758,  0.2999, -0.5338,  ..., -1.0883, -0.4052,  0.9804],\n",
            "        [-0.2713,  0.2953, -0.5308,  ..., -1.5474, -0.9582,  0.7113],\n",
            "        [-0.2722,  0.2975, -0.5298,  ..., -1.2028, -0.8192,  0.6475]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0274,  0.0299, -0.0528,  ..., -0.0964, -0.0712,  0.0484],\n",
            "        [-0.0275,  0.0305, -0.0547,  ..., -0.0994, -0.0479,  0.1381],\n",
            "        [-0.0276,  0.0301, -0.0526,  ..., -0.0850, -0.0633,  0.0464],\n",
            "        ...,\n",
            "        [-0.0273,  0.0299, -0.0530,  ..., -0.1061, -0.0713,  0.0604],\n",
            "        [-0.0274,  0.0305, -0.0547,  ..., -0.1070, -0.0490,  0.1376],\n",
            "        [-0.0273,  0.0299, -0.0529,  ..., -0.0934, -0.0739,  0.0441]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2741,  0.2991, -0.5278,  ..., -0.9643, -0.7121,  0.4841],\n",
            "        [-0.2745,  0.3048, -0.5467,  ..., -0.9942, -0.4786,  1.3805],\n",
            "        [-0.2760,  0.3005, -0.5258,  ..., -0.8500, -0.6335,  0.4643],\n",
            "        ...,\n",
            "        [-0.2732,  0.2992, -0.5303,  ..., -1.0610, -0.7126,  0.6042],\n",
            "        [-0.2736,  0.3051, -0.5474,  ..., -1.0704, -0.4895,  1.3759],\n",
            "        [-0.2726,  0.2985, -0.5290,  ..., -0.9339, -0.7386,  0.4407]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0272,  0.0298, -0.0532,  ..., -0.0997, -0.0739,  0.0569],\n",
            "        [-0.0275,  0.0298, -0.0525,  ..., -0.1097, -0.0695,  0.0511],\n",
            "        [-0.0274,  0.0307, -0.0559,  ..., -0.1137, -0.0311,  0.1954],\n",
            "        ...,\n",
            "        [-0.0272,  0.0294, -0.0529,  ..., -0.1675, -0.0990,  0.0768],\n",
            "        [-0.0274,  0.0298, -0.0527,  ..., -0.0869, -0.0639,  0.0445],\n",
            "        [-0.0275,  0.0300, -0.0525,  ..., -0.0810, -0.0701,  0.0350]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2720,  0.2980, -0.5317,  ..., -0.9967, -0.7391,  0.5691],\n",
            "        [-0.2747,  0.2977, -0.5252,  ..., -1.0972, -0.6952,  0.5114],\n",
            "        [-0.2737,  0.3067, -0.5586,  ..., -1.1367, -0.3114,  1.9537],\n",
            "        ...,\n",
            "        [-0.2719,  0.2941, -0.5286,  ..., -1.6752, -0.9903,  0.7677],\n",
            "        [-0.2740,  0.2982, -0.5271,  ..., -0.8686, -0.6389,  0.4450],\n",
            "        [-0.2746,  0.2997, -0.5251,  ..., -0.8104, -0.7010,  0.3504]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0271,  0.0296, -0.0528,  ..., -0.1139, -0.0807,  0.0527],\n",
            "        [-0.0273,  0.0304, -0.0548,  ..., -0.0935, -0.0390,  0.1400],\n",
            "        [-0.0273,  0.0295, -0.0525,  ..., -0.1503, -0.0912,  0.0728],\n",
            "        ...,\n",
            "        [-0.0268,  0.0296, -0.0533,  ..., -0.1102, -0.0997,  0.0527],\n",
            "        [-0.0271,  0.0295, -0.0527,  ..., -0.1364, -0.0933,  0.0678],\n",
            "        [-0.0272,  0.0295, -0.0526,  ..., -0.1416, -0.0907,  0.0661]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2714,  0.2960, -0.5281,  ..., -1.1387, -0.8073,  0.5274],\n",
            "        [-0.2727,  0.3044, -0.5480,  ..., -0.9350, -0.3897,  1.3999],\n",
            "        [-0.2726,  0.2947, -0.5249,  ..., -1.5033, -0.9117,  0.7284],\n",
            "        ...,\n",
            "        [-0.2679,  0.2964, -0.5329,  ..., -1.1024, -0.9974,  0.5271],\n",
            "        [-0.2708,  0.2953, -0.5273,  ..., -1.3642, -0.9331,  0.6777],\n",
            "        [-0.2723,  0.2946, -0.5263,  ..., -1.4160, -0.9065,  0.6608]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0274,  0.0297, -0.0522,  ..., -0.0943, -0.0667,  0.0475],\n",
            "        [-0.0274,  0.0298, -0.0527,  ..., -0.0925, -0.0516,  0.0760],\n",
            "        [-0.0270,  0.0293, -0.0526,  ..., -0.1411, -0.0940,  0.0652],\n",
            "        ...,\n",
            "        [-0.0272,  0.0296, -0.0529,  ..., -0.1121, -0.0673,  0.0782],\n",
            "        [-0.0269,  0.0293, -0.0528,  ..., -0.1531, -0.1082,  0.0731],\n",
            "        [-0.0276,  0.0297, -0.0521,  ..., -0.0910, -0.0648,  0.0440]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2736,  0.2966, -0.5219,  ..., -0.9426, -0.6669,  0.4749],\n",
            "        [-0.2738,  0.2975, -0.5265,  ..., -0.9252, -0.5162,  0.7601],\n",
            "        [-0.2699,  0.2933, -0.5258,  ..., -1.4108, -0.9403,  0.6519],\n",
            "        ...,\n",
            "        [-0.2720,  0.2958, -0.5289,  ..., -1.1206, -0.6732,  0.7817],\n",
            "        [-0.2687,  0.2932, -0.5279,  ..., -1.5314, -1.0825,  0.7315],\n",
            "        [-0.2755,  0.2966, -0.5208,  ..., -0.9105, -0.6484,  0.4399]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0271,  0.0302, -0.0546,  ..., -0.0960, -0.0479,  0.1503],\n",
            "        [-0.0274,  0.0302, -0.0540,  ..., -0.1084, -0.0277,  0.1753],\n",
            "        [-0.0270,  0.0295, -0.0523,  ..., -0.0985, -0.0890,  0.0481],\n",
            "        ...,\n",
            "        [-0.0270,  0.0303, -0.0543,  ..., -0.0997, -0.0318,  0.1520],\n",
            "        [-0.0271,  0.0294, -0.0521,  ..., -0.1133, -0.0814,  0.0570],\n",
            "        [-0.0268,  0.0292, -0.0525,  ..., -0.1555, -0.1116,  0.0708]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2708,  0.3017, -0.5463,  ..., -0.9600, -0.4794,  1.5026],\n",
            "        [-0.2743,  0.3015, -0.5398,  ..., -1.0838, -0.2772,  1.7534],\n",
            "        [-0.2698,  0.2951, -0.5230,  ..., -0.9855, -0.8904,  0.4810],\n",
            "        ...,\n",
            "        [-0.2695,  0.3026, -0.5429,  ..., -0.9966, -0.3180,  1.5200],\n",
            "        [-0.2711,  0.2944, -0.5206,  ..., -1.1334, -0.8138,  0.5701],\n",
            "        [-0.2680,  0.2916, -0.5254,  ..., -1.5545, -1.1164,  0.7080]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0269,  0.0293, -0.0523,  ..., -0.1167, -0.0839,  0.0614],\n",
            "        [-0.0271,  0.0301, -0.0541,  ..., -0.0913, -0.0442,  0.1389],\n",
            "        [-0.0273,  0.0295, -0.0520,  ..., -0.0919, -0.0535,  0.0579],\n",
            "        ...,\n",
            "        [-0.0268,  0.0293, -0.0524,  ..., -0.1114, -0.0813,  0.0691],\n",
            "        [-0.0268,  0.0292, -0.0523,  ..., -0.1211, -0.0895,  0.0522],\n",
            "        [-0.0276,  0.0296, -0.0516,  ..., -0.0673, -0.0561,  0.0316]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2693,  0.2930, -0.5226,  ..., -1.1670, -0.8394,  0.6143],\n",
            "        [-0.2706,  0.3013, -0.5414,  ..., -0.9130, -0.4422,  1.3887],\n",
            "        [-0.2734,  0.2955, -0.5202,  ..., -0.9189, -0.5354,  0.5786],\n",
            "        ...,\n",
            "        [-0.2678,  0.2931, -0.5238,  ..., -1.1139, -0.8134,  0.6910],\n",
            "        [-0.2684,  0.2917, -0.5232,  ..., -1.2112, -0.8949,  0.5217],\n",
            "        [-0.2756,  0.2960, -0.5160,  ..., -0.6726, -0.5606,  0.3162]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0271,  0.0293, -0.0519,  ..., -0.1115, -0.0776,  0.0501],\n",
            "        [-0.0273,  0.0294, -0.0519,  ..., -0.0987, -0.0643,  0.0480],\n",
            "        [-0.0271,  0.0293, -0.0519,  ..., -0.1071, -0.0781,  0.0510],\n",
            "        ...,\n",
            "        [-0.0275,  0.0303, -0.0547,  ..., -0.1148, -0.0157,  0.1990],\n",
            "        [-0.0269,  0.0293, -0.0523,  ..., -0.1106, -0.0808,  0.0593],\n",
            "        [-0.0269,  0.0294, -0.0525,  ..., -0.1042, -0.0657,  0.0658]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2710,  0.2929, -0.5187,  ..., -1.1155, -0.7764,  0.5007],\n",
            "        [-0.2727,  0.2942, -0.5186,  ..., -0.9865, -0.6433,  0.4799],\n",
            "        [-0.2711,  0.2930, -0.5190,  ..., -1.0706, -0.7814,  0.5102],\n",
            "        ...,\n",
            "        [-0.2752,  0.3035, -0.5469,  ..., -1.1479, -0.1574,  1.9896],\n",
            "        [-0.2688,  0.2929, -0.5234,  ..., -1.1059, -0.8079,  0.5929],\n",
            "        [-0.2689,  0.2943, -0.5248,  ..., -1.0423, -0.6571,  0.6576]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0270,  0.0292, -0.0519,  ..., -0.1330, -0.0854,  0.0619],\n",
            "        [-0.0271,  0.0292, -0.0518,  ..., -0.1301, -0.0840,  0.0591],\n",
            "        [-0.0272,  0.0300, -0.0534,  ..., -0.1000, -0.0445,  0.1373],\n",
            "        ...,\n",
            "        [-0.0274,  0.0295, -0.0518,  ..., -0.0664, -0.0494,  0.0390],\n",
            "        [-0.0268,  0.0294, -0.0522,  ..., -0.1051, -0.0915,  0.0551],\n",
            "        [-0.0269,  0.0293, -0.0520,  ..., -0.1033, -0.0849,  0.0504]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2704,  0.2920, -0.5188,  ..., -1.3304, -0.8540,  0.6189],\n",
            "        [-0.2709,  0.2922, -0.5180,  ..., -1.3010, -0.8399,  0.5915],\n",
            "        [-0.2719,  0.2999, -0.5339,  ..., -1.0000, -0.4450,  1.3728],\n",
            "        ...,\n",
            "        [-0.2743,  0.2955, -0.5179,  ..., -0.6644, -0.4936,  0.3905],\n",
            "        [-0.2685,  0.2936, -0.5215,  ..., -1.0506, -0.9152,  0.5506],\n",
            "        [-0.2694,  0.2933, -0.5198,  ..., -1.0329, -0.8492,  0.5040]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0272,  0.0300, -0.0535,  ..., -0.0883, -0.0457,  0.1124],\n",
            "        [-0.0274,  0.0295, -0.0521,  ..., -0.0989, -0.0445,  0.0779],\n",
            "        [-0.0272,  0.0301, -0.0538,  ..., -0.1025, -0.0386,  0.1495],\n",
            "        ...,\n",
            "        [-0.0271,  0.0293, -0.0518,  ..., -0.1091, -0.0806,  0.0513],\n",
            "        [-0.0273,  0.0295, -0.0518,  ..., -0.0668, -0.0506,  0.0363],\n",
            "        [-0.0270,  0.0293, -0.0519,  ..., -0.1048, -0.0822,  0.0521]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2718,  0.2997, -0.5353,  ..., -0.8825, -0.4574,  1.1240],\n",
            "        [-0.2741,  0.2951, -0.5213,  ..., -0.9887, -0.4448,  0.7793],\n",
            "        [-0.2721,  0.3010, -0.5379,  ..., -1.0252, -0.3857,  1.4955],\n",
            "        ...,\n",
            "        [-0.2714,  0.2933, -0.5179,  ..., -1.0908, -0.8058,  0.5126],\n",
            "        [-0.2734,  0.2954, -0.5177,  ..., -0.6684, -0.5061,  0.3635],\n",
            "        [-0.2702,  0.2932, -0.5186,  ..., -1.0478, -0.8217,  0.5206]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0274,  0.0294, -0.0514,  ..., -0.0998, -0.0770,  0.0456],\n",
            "        [-0.0276,  0.0294, -0.0514,  ..., -0.0838, -0.0616,  0.0358],\n",
            "        [-0.0269,  0.0293, -0.0521,  ..., -0.1111, -0.0935,  0.0509],\n",
            "        ...,\n",
            "        [-0.0272,  0.0294, -0.0516,  ..., -0.0906, -0.0685,  0.0377],\n",
            "        [-0.0271,  0.0294, -0.0522,  ..., -0.0906, -0.0668,  0.0545],\n",
            "        [-0.0274,  0.0294, -0.0516,  ..., -0.0864, -0.0664,  0.0422]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2736,  0.2937, -0.5145,  ..., -0.9977, -0.7699,  0.4557],\n",
            "        [-0.2764,  0.2943, -0.5144,  ..., -0.8382, -0.6156,  0.3579],\n",
            "        [-0.2693,  0.2927, -0.5206,  ..., -1.1113, -0.9346,  0.5094],\n",
            "        ...,\n",
            "        [-0.2725,  0.2936, -0.5162,  ..., -0.9060, -0.6852,  0.3768],\n",
            "        [-0.2710,  0.2937, -0.5216,  ..., -0.9058, -0.6678,  0.5448],\n",
            "        [-0.2741,  0.2943, -0.5155,  ..., -0.8639, -0.6636,  0.4224]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0270,  0.0292, -0.0518,  ..., -0.1260, -0.0878,  0.0583],\n",
            "        [-0.0271,  0.0293, -0.0517,  ..., -0.1120, -0.0821,  0.0555],\n",
            "        [-0.0274,  0.0301, -0.0537,  ..., -0.1054, -0.0249,  0.1705],\n",
            "        ...,\n",
            "        [-0.0270,  0.0292, -0.0518,  ..., -0.1208, -0.0884,  0.0537],\n",
            "        [-0.0273,  0.0294, -0.0515,  ..., -0.0975, -0.0696,  0.0505],\n",
            "        [-0.0273,  0.0294, -0.0516,  ..., -0.0766, -0.0655,  0.0328]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2702,  0.2915, -0.5181,  ..., -1.2599, -0.8777,  0.5825],\n",
            "        [-0.2706,  0.2931, -0.5167,  ..., -1.1204, -0.8210,  0.5554],\n",
            "        [-0.2741,  0.3007, -0.5372,  ..., -1.0543, -0.2489,  1.7050],\n",
            "        ...,\n",
            "        [-0.2700,  0.2917, -0.5178,  ..., -1.2076, -0.8838,  0.5373],\n",
            "        [-0.2731,  0.2935, -0.5154,  ..., -0.9745, -0.6957,  0.5048],\n",
            "        [-0.2728,  0.2938, -0.5156,  ..., -0.7660, -0.6545,  0.3277]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0276,  0.0295, -0.0513,  ..., -0.0781, -0.0675,  0.0332],\n",
            "        [-0.0274,  0.0293, -0.0515,  ..., -0.1118, -0.0768,  0.0465],\n",
            "        [-0.0269,  0.0292, -0.0521,  ..., -0.1108, -0.0954,  0.0524],\n",
            "        ...,\n",
            "        [-0.0275,  0.0295, -0.0515,  ..., -0.0704, -0.0584,  0.0335],\n",
            "        [-0.0274,  0.0294, -0.0513,  ..., -0.0953, -0.0667,  0.0410],\n",
            "        [-0.0270,  0.0291, -0.0517,  ..., -0.1346, -0.0934,  0.0590]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2757,  0.2950, -0.5131,  ..., -0.7811, -0.6749,  0.3322],\n",
            "        [-0.2735,  0.2926, -0.5151,  ..., -1.1179, -0.7683,  0.4648],\n",
            "        [-0.2690,  0.2925, -0.5209,  ..., -1.1083, -0.9536,  0.5241],\n",
            "        ...,\n",
            "        [-0.2747,  0.2945, -0.5147,  ..., -0.7041, -0.5844,  0.3352],\n",
            "        [-0.2745,  0.2939, -0.5134,  ..., -0.9531, -0.6666,  0.4097],\n",
            "        [-0.2705,  0.2912, -0.5174,  ..., -1.3462, -0.9344,  0.5904]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0272,  0.0293, -0.0517,  ..., -0.0958, -0.0773,  0.0398],\n",
            "        [-0.0271,  0.0293, -0.0518,  ..., -0.0930, -0.0770,  0.0410],\n",
            "        [-0.0274,  0.0295, -0.0514,  ..., -0.0871, -0.0658,  0.0429],\n",
            "        ...,\n",
            "        [-0.0272,  0.0292, -0.0516,  ..., -0.1235, -0.0866,  0.0564],\n",
            "        [-0.0272,  0.0293, -0.0517,  ..., -0.0973, -0.0794,  0.0396],\n",
            "        [-0.0270,  0.0292, -0.0519,  ..., -0.1156, -0.0855,  0.0463]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2720,  0.2933, -0.5172,  ..., -0.9584, -0.7727,  0.3978],\n",
            "        [-0.2710,  0.2931, -0.5183,  ..., -0.9303, -0.7704,  0.4103],\n",
            "        [-0.2743,  0.2946, -0.5140,  ..., -0.8708, -0.6579,  0.4288],\n",
            "        ...,\n",
            "        [-0.2720,  0.2922, -0.5158,  ..., -1.2352, -0.8664,  0.5640],\n",
            "        [-0.2720,  0.2925, -0.5168,  ..., -0.9727, -0.7944,  0.3962],\n",
            "        [-0.2704,  0.2915, -0.5192,  ..., -1.1560, -0.8545,  0.4633]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0274,  0.0294, -0.0515,  ..., -0.0836, -0.0641,  0.0322],\n",
            "        [-0.0274,  0.0300, -0.0538,  ..., -0.0998, -0.0373,  0.1286],\n",
            "        [-0.0273,  0.0294, -0.0518,  ..., -0.0856, -0.0631,  0.0457],\n",
            "        ...,\n",
            "        [-0.0274,  0.0295, -0.0519,  ..., -0.0829, -0.0578,  0.0551],\n",
            "        [-0.0270,  0.0291, -0.0520,  ..., -0.1269, -0.0905,  0.0517],\n",
            "        [-0.0274,  0.0294, -0.0516,  ..., -0.0886, -0.0708,  0.0341]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2744,  0.2940, -0.5151,  ..., -0.8356, -0.6405,  0.3215],\n",
            "        [-0.2743,  0.2998, -0.5382,  ..., -0.9977, -0.3730,  1.2860],\n",
            "        [-0.2729,  0.2940, -0.5182,  ..., -0.8555, -0.6311,  0.4572],\n",
            "        ...,\n",
            "        [-0.2744,  0.2949, -0.5193,  ..., -0.8287, -0.5778,  0.5511],\n",
            "        [-0.2702,  0.2914, -0.5197,  ..., -1.2693, -0.9054,  0.5171],\n",
            "        [-0.2737,  0.2942, -0.5158,  ..., -0.8863, -0.7075,  0.3407]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0274,  0.0295, -0.0515,  ..., -0.0761, -0.0632,  0.0366],\n",
            "        [-0.0275,  0.0295, -0.0518,  ..., -0.0838, -0.0521,  0.0605],\n",
            "        [-0.0273,  0.0294, -0.0515,  ..., -0.0937, -0.0802,  0.0375],\n",
            "        ...,\n",
            "        [-0.0273,  0.0294, -0.0516,  ..., -0.0912, -0.0791,  0.0424],\n",
            "        [-0.0274,  0.0300, -0.0536,  ..., -0.1034, -0.0260,  0.1484],\n",
            "        [-0.0271,  0.0293, -0.0516,  ..., -0.1085, -0.0871,  0.0581]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2743,  0.2947, -0.5152,  ..., -0.7611, -0.6320,  0.3661],\n",
            "        [-0.2753,  0.2947, -0.5178,  ..., -0.8381, -0.5207,  0.6054],\n",
            "        [-0.2726,  0.2939, -0.5153,  ..., -0.9366, -0.8018,  0.3755],\n",
            "        ...,\n",
            "        [-0.2730,  0.2938, -0.5161,  ..., -0.9124, -0.7906,  0.4244],\n",
            "        [-0.2743,  0.3000, -0.5356,  ..., -1.0340, -0.2595,  1.4843],\n",
            "        [-0.2711,  0.2933, -0.5157,  ..., -1.0845, -0.8707,  0.5807]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0271,  0.0292, -0.0515,  ..., -0.1242, -0.0888,  0.0565],\n",
            "        [-0.0274,  0.0294, -0.0519,  ..., -0.0840, -0.0501,  0.0732],\n",
            "        [-0.0271,  0.0293, -0.0519,  ..., -0.0836, -0.0742,  0.0401],\n",
            "        ...,\n",
            "        [-0.0273,  0.0292, -0.0514,  ..., -0.1059, -0.0755,  0.0446],\n",
            "        [-0.0273,  0.0299, -0.0535,  ..., -0.0945, -0.0446,  0.1362],\n",
            "        [-0.0272,  0.0292, -0.0516,  ..., -0.0998, -0.0749,  0.0390]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2712,  0.2918, -0.5146,  ..., -1.2423, -0.8881,  0.5650],\n",
            "        [-0.2735,  0.2941, -0.5188,  ..., -0.8400, -0.5010,  0.7322],\n",
            "        [-0.2706,  0.2934, -0.5195,  ..., -0.8362, -0.7417,  0.4005],\n",
            "        ...,\n",
            "        [-0.2733,  0.2925, -0.5144,  ..., -1.0592, -0.7545,  0.4455],\n",
            "        [-0.2731,  0.2992, -0.5349,  ..., -0.9446, -0.4462,  1.3620],\n",
            "        [-0.2725,  0.2920, -0.5156,  ..., -0.9979, -0.7488,  0.3903]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0274,  0.0293, -0.0512,  ..., -0.0974, -0.0729,  0.0320],\n",
            "        [-0.0271,  0.0291, -0.0515,  ..., -0.1222, -0.0871,  0.0491],\n",
            "        [-0.0272,  0.0293, -0.0515,  ..., -0.0943, -0.0747,  0.0462],\n",
            "        ...,\n",
            "        [-0.0274,  0.0293, -0.0513,  ..., -0.0863, -0.0689,  0.0303],\n",
            "        [-0.0273,  0.0292, -0.0513,  ..., -0.1012, -0.0803,  0.0466],\n",
            "        [-0.0271,  0.0293, -0.0520,  ..., -0.1030, -0.0627,  0.0617]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2740,  0.2927, -0.5120,  ..., -0.9742, -0.7286,  0.3197],\n",
            "        [-0.2713,  0.2912, -0.5148,  ..., -1.2220, -0.8705,  0.4908],\n",
            "        [-0.2717,  0.2927, -0.5147,  ..., -0.9430, -0.7469,  0.4617],\n",
            "        ...,\n",
            "        [-0.2742,  0.2930, -0.5126,  ..., -0.8627, -0.6890,  0.3026],\n",
            "        [-0.2726,  0.2920, -0.5125,  ..., -1.0125, -0.8028,  0.4661],\n",
            "        [-0.2711,  0.2928, -0.5202,  ..., -1.0298, -0.6273,  0.6168]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0271,  0.0291, -0.0513,  ..., -0.1167, -0.0897,  0.0505],\n",
            "        [-0.0270,  0.0292, -0.0516,  ..., -0.0923, -0.0738,  0.0452],\n",
            "        [-0.0270,  0.0289, -0.0514,  ..., -0.1339, -0.0958,  0.0499],\n",
            "        ...,\n",
            "        [-0.0269,  0.0292, -0.0515,  ..., -0.0634, -0.0749,  0.0244],\n",
            "        [-0.0270,  0.0293, -0.0517,  ..., -0.0849, -0.0709,  0.0484],\n",
            "        [-0.0272,  0.0292, -0.0512,  ..., -0.0765, -0.0702,  0.0367]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2706,  0.2906, -0.5130,  ..., -1.1673, -0.8974,  0.5048],\n",
            "        [-0.2701,  0.2915, -0.5165,  ..., -0.9225, -0.7385,  0.4522],\n",
            "        [-0.2703,  0.2892, -0.5145,  ..., -1.3389, -0.9583,  0.4990],\n",
            "        ...,\n",
            "        [-0.2689,  0.2920, -0.5148,  ..., -0.6341, -0.7494,  0.2444],\n",
            "        [-0.2704,  0.2926, -0.5165,  ..., -0.8493, -0.7094,  0.4841],\n",
            "        [-0.2723,  0.2924, -0.5115,  ..., -0.7650, -0.7016,  0.3673]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0269,  0.0290, -0.0514,  ..., -0.1065, -0.0867,  0.0462],\n",
            "        [-0.0272,  0.0291, -0.0511,  ..., -0.1021, -0.0746,  0.0443],\n",
            "        [-0.0269,  0.0301, -0.0540,  ..., -0.1000, -0.0397,  0.1358],\n",
            "        ...,\n",
            "        [-0.0270,  0.0291, -0.0515,  ..., -0.0913, -0.0773,  0.0391],\n",
            "        [-0.0272,  0.0289, -0.0510,  ..., -0.1280, -0.0894,  0.0523],\n",
            "        [-0.0271,  0.0291, -0.0516,  ..., -0.0964, -0.0627,  0.0544]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2691,  0.2898, -0.5138,  ..., -1.0655, -0.8674,  0.4621],\n",
            "        [-0.2716,  0.2908, -0.5110,  ..., -1.0212, -0.7461,  0.4435],\n",
            "        [-0.2693,  0.3010, -0.5397,  ..., -1.0002, -0.3970,  1.3581],\n",
            "        ...,\n",
            "        [-0.2700,  0.2911, -0.5153,  ..., -0.9133, -0.7730,  0.3914],\n",
            "        [-0.2718,  0.2895, -0.5100,  ..., -1.2803, -0.8935,  0.5230],\n",
            "        [-0.2713,  0.2910, -0.5155,  ..., -0.9642, -0.6269,  0.5441]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0271,  0.0290, -0.0511,  ..., -0.1146, -0.0810,  0.0449],\n",
            "        [-0.0269,  0.0289, -0.0515,  ..., -0.1125, -0.0874,  0.0435],\n",
            "        [-0.0269,  0.0291, -0.0516,  ..., -0.0862, -0.0876,  0.0301],\n",
            "        ...,\n",
            "        [-0.0272,  0.0291, -0.0510,  ..., -0.1067, -0.0760,  0.0404],\n",
            "        [-0.0271,  0.0299, -0.0534,  ..., -0.0884, -0.0504,  0.1117],\n",
            "        [-0.0273,  0.0298, -0.0528,  ..., -0.0887, -0.0517,  0.0906]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2709,  0.2902, -0.5111,  ..., -1.1458, -0.8103,  0.4485],\n",
            "        [-0.2686,  0.2893, -0.5152,  ..., -1.1253, -0.8735,  0.4346],\n",
            "        [-0.2686,  0.2906, -0.5161,  ..., -0.8617, -0.8759,  0.3014],\n",
            "        ...,\n",
            "        [-0.2721,  0.2905, -0.5102,  ..., -1.0669, -0.7603,  0.4037],\n",
            "        [-0.2714,  0.2989, -0.5336,  ..., -0.8838, -0.5039,  1.1173],\n",
            "        [-0.2729,  0.2977, -0.5283,  ..., -0.8867, -0.5168,  0.9065]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Old tensor([[-0.0272,  0.0291, -0.0512,  ..., -0.1035, -0.0758,  0.0373],\n",
            "        [-0.0270,  0.0290, -0.0512,  ..., -0.1238, -0.0919,  0.0517],\n",
            "        [-0.0274,  0.0298, -0.0531,  ..., -0.0981, -0.0389,  0.1391],\n",
            "        ...,\n",
            "        [-0.0273,  0.0297, -0.0529,  ..., -0.0978, -0.0445,  0.1251],\n",
            "        [-0.0271,  0.0291, -0.0513,  ..., -0.0998, -0.0794,  0.0399],\n",
            "        [-0.0271,  0.0290, -0.0514,  ..., -0.1080, -0.0799,  0.0421]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "New tensor([[-0.2721,  0.2907, -0.5116,  ..., -1.0347, -0.7583,  0.3729],\n",
            "        [-0.2701,  0.2901, -0.5120,  ..., -1.2380, -0.9186,  0.5166],\n",
            "        [-0.2740,  0.2975, -0.5308,  ..., -0.9812, -0.3887,  1.3909],\n",
            "        ...,\n",
            "        [-0.2731,  0.2972, -0.5295,  ..., -0.9784, -0.4448,  1.2508],\n",
            "        [-0.2714,  0.2910, -0.5129,  ..., -0.9979, -0.7945,  0.3992],\n",
            "        [-0.2707,  0.2902, -0.5141,  ..., -1.0803, -0.7987,  0.4207]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "Training loss 0.009827343747019768\n",
            "Old tensor([[-0.0269,  0.0291, -0.0519,  ..., -0.1170, -0.0899,  0.0520],\n",
            "        [-0.0270,  0.0291, -0.0516,  ..., -0.0863, -0.0732,  0.0401],\n",
            "        [-0.0274,  0.0293, -0.0517,  ..., -0.0925, -0.0460,  0.0758],\n",
            "        ...,\n",
            "        [-0.0271,  0.0291, -0.0514,  ..., -0.1088, -0.0897,  0.0390],\n",
            "        [-0.0271,  0.0291, -0.0513,  ..., -0.0972, -0.0787,  0.0400],\n",
            "        [-0.0271,  0.0292, -0.0514,  ..., -0.0899, -0.0768,  0.0419]])\n",
            "New tensor([[-0.2692,  0.2908, -0.5185,  ..., -1.1705, -0.8988,  0.5203],\n",
            "        [-0.2696,  0.2914, -0.5162,  ..., -0.8628, -0.7315,  0.4012],\n",
            "        [-0.2738,  0.2930, -0.5169,  ..., -0.9254, -0.4599,  0.7577],\n",
            "        ...,\n",
            "        [-0.2710,  0.2909, -0.5145,  ..., -1.0882, -0.8975,  0.3899],\n",
            "        [-0.2708,  0.2911, -0.5133,  ..., -0.9719, -0.7869,  0.3995],\n",
            "        [-0.2709,  0.2919, -0.5141,  ..., -0.8986, -0.7680,  0.4189]])\n",
            "Old tensor([[-0.0273,  0.0299, -0.0530,  ..., -0.0860, -0.0412,  0.1128],\n",
            "        [-0.0274,  0.0294, -0.0512,  ..., -0.0616, -0.0599,  0.0249],\n",
            "        [-0.0269,  0.0290, -0.0515,  ..., -0.1328, -0.0983,  0.0493],\n",
            "        ...,\n",
            "        [-0.0274,  0.0298, -0.0529,  ..., -0.0925, -0.0412,  0.1248],\n",
            "        [-0.0273,  0.0293, -0.0512,  ..., -0.0793, -0.0670,  0.0361],\n",
            "        [-0.0270,  0.0290, -0.0515,  ..., -0.1147, -0.0938,  0.0413]])\n",
            "New tensor([[-0.2727,  0.2985, -0.5302,  ..., -0.8604, -0.4118,  1.1281],\n",
            "        [-0.2739,  0.2935, -0.5125,  ..., -0.6159, -0.5991,  0.2493],\n",
            "        [-0.2693,  0.2895, -0.5150,  ..., -1.3279, -0.9827,  0.4926],\n",
            "        ...,\n",
            "        [-0.2745,  0.2979, -0.5292,  ..., -0.9255, -0.4122,  1.2477],\n",
            "        [-0.2735,  0.2926, -0.5118,  ..., -0.7928, -0.6704,  0.3606],\n",
            "        [-0.2699,  0.2904, -0.5146,  ..., -1.1474, -0.9379,  0.4130]])\n",
            "Old tensor([[-0.0274,  0.0298, -0.0530,  ..., -0.0847, -0.0468,  0.1085],\n",
            "        [-0.0273,  0.0298, -0.0531,  ..., -0.0846, -0.0603,  0.0999],\n",
            "        [-0.0273,  0.0298, -0.0534,  ..., -0.0947, -0.0577,  0.1048],\n",
            "        ...,\n",
            "        [-0.0273,  0.0292, -0.0511,  ..., -0.1008, -0.0733,  0.0401],\n",
            "        [-0.0273,  0.0298, -0.0530,  ..., -0.0861, -0.0491,  0.1066],\n",
            "        [-0.0269,  0.0291, -0.0519,  ..., -0.0967, -0.0783,  0.0460]])\n",
            "New tensor([[-0.2737,  0.2978, -0.5295,  ..., -0.8471, -0.4676,  1.0848],\n",
            "        [-0.2730,  0.2982, -0.5315,  ..., -0.8457, -0.6028,  0.9989],\n",
            "        [-0.2728,  0.2984, -0.5340,  ..., -0.9473, -0.5770,  1.0483],\n",
            "        ...,\n",
            "        [-0.2729,  0.2919, -0.5111,  ..., -1.0079, -0.7332,  0.4010],\n",
            "        [-0.2733,  0.2979, -0.5298,  ..., -0.8607, -0.4908,  1.0657],\n",
            "        [-0.2687,  0.2911, -0.5186,  ..., -0.9670, -0.7835,  0.4602]])\n",
            "Old tensor([[-0.0274,  0.0298, -0.0530,  ..., -0.0905, -0.0468,  0.1039],\n",
            "        [-0.0271,  0.0292, -0.0514,  ..., -0.0860, -0.0711,  0.0344],\n",
            "        [-0.0271,  0.0292, -0.0514,  ..., -0.0673, -0.0676,  0.0280],\n",
            "        ...,\n",
            "        [-0.0274,  0.0293, -0.0516,  ..., -0.0774, -0.0563,  0.0564],\n",
            "        [-0.0274,  0.0294, -0.0513,  ..., -0.0660, -0.0557,  0.0356],\n",
            "        [-0.0274,  0.0293, -0.0512,  ..., -0.0673, -0.0544,  0.0341]])\n",
            "New tensor([[-0.2740,  0.2984, -0.5297,  ..., -0.9051, -0.4684,  1.0387],\n",
            "        [-0.2715,  0.2920, -0.5138,  ..., -0.8603, -0.7110,  0.3444],\n",
            "        [-0.2710,  0.2919, -0.5137,  ..., -0.6728, -0.6763,  0.2799],\n",
            "        ...,\n",
            "        [-0.2736,  0.2931, -0.5163,  ..., -0.7740, -0.5629,  0.5643],\n",
            "        [-0.2744,  0.2935, -0.5134,  ..., -0.6603, -0.5571,  0.3561],\n",
            "        [-0.2742,  0.2934, -0.5121,  ..., -0.6730, -0.5441,  0.3412]])\n",
            "Old tensor([[-0.0275,  0.0292, -0.0510,  ..., -0.0828, -0.0671,  0.0285],\n",
            "        [-0.0269,  0.0291, -0.0516,  ..., -0.1033, -0.0881,  0.0443],\n",
            "        [-0.0270,  0.0291, -0.0514,  ..., -0.0987, -0.0853,  0.0402],\n",
            "        ...,\n",
            "        [-0.0275,  0.0293, -0.0513,  ..., -0.0628, -0.0479,  0.0425],\n",
            "        [-0.0277,  0.0293, -0.0509,  ..., -0.0650, -0.0574,  0.0243],\n",
            "        [-0.0271,  0.0291, -0.0513,  ..., -0.1143, -0.0863,  0.0430]])\n",
            "New tensor([[-0.2753,  0.2918, -0.5101,  ..., -0.8279, -0.6707,  0.2853],\n",
            "        [-0.2687,  0.2906, -0.5156,  ..., -1.0332, -0.8806,  0.4432],\n",
            "        [-0.2705,  0.2914, -0.5140,  ..., -0.9874, -0.8533,  0.4018],\n",
            "        ...,\n",
            "        [-0.2752,  0.2934, -0.5134,  ..., -0.6280, -0.4789,  0.4247],\n",
            "        [-0.2768,  0.2932, -0.5091,  ..., -0.6504, -0.5737,  0.2426],\n",
            "        [-0.2709,  0.2910, -0.5129,  ..., -1.1430, -0.8632,  0.4298]])\n",
            "Old tensor([[-0.0274,  0.0293, -0.0515,  ..., -0.0863, -0.0578,  0.0489],\n",
            "        [-0.0272,  0.0292, -0.0514,  ..., -0.0849, -0.0779,  0.0317],\n",
            "        [-0.0274,  0.0293, -0.0512,  ..., -0.0752, -0.0608,  0.0337],\n",
            "        ...,\n",
            "        [-0.0268,  0.0290, -0.0514,  ..., -0.1275, -0.1022,  0.0529],\n",
            "        [-0.0270,  0.0289, -0.0514,  ..., -0.1298, -0.0936,  0.0480],\n",
            "        [-0.0272,  0.0299, -0.0532,  ..., -0.1020, -0.0413,  0.1154]])\n",
            "New tensor([[-0.2736,  0.2929, -0.5145,  ..., -0.8627, -0.5784,  0.4894],\n",
            "        [-0.2722,  0.2916, -0.5140,  ..., -0.8493, -0.7788,  0.3167],\n",
            "        [-0.2740,  0.2929, -0.5123,  ..., -0.7519, -0.6081,  0.3369],\n",
            "        ...,\n",
            "        [-0.2681,  0.2899, -0.5142,  ..., -1.2750, -1.0224,  0.5286],\n",
            "        [-0.2704,  0.2894, -0.5143,  ..., -1.2983, -0.9357,  0.4799],\n",
            "        [-0.2716,  0.2994, -0.5321,  ..., -1.0196, -0.4126,  1.1545]])\n",
            "Old tensor([[-0.0272,  0.0292, -0.0513,  ..., -0.0807, -0.0673,  0.0347],\n",
            "        [-0.0270,  0.0290, -0.0514,  ..., -0.1237, -0.0894,  0.0491],\n",
            "        [-0.0273,  0.0298, -0.0532,  ..., -0.0922, -0.0447,  0.1066],\n",
            "        ...,\n",
            "        [-0.0270,  0.0291, -0.0514,  ..., -0.0995, -0.0821,  0.0409],\n",
            "        [-0.0268,  0.0291, -0.0519,  ..., -0.1061, -0.0803,  0.0566],\n",
            "        [-0.0269,  0.0289, -0.0514,  ..., -0.1346, -0.0955,  0.0505]])\n",
            "New tensor([[-0.2717,  0.2923, -0.5134,  ..., -0.8066, -0.6729,  0.3466],\n",
            "        [-0.2703,  0.2903, -0.5138,  ..., -1.2366, -0.8939,  0.4910],\n",
            "        [-0.2728,  0.2982, -0.5315,  ..., -0.9218, -0.4475,  1.0664],\n",
            "        ...,\n",
            "        [-0.2703,  0.2910, -0.5142,  ..., -0.9952, -0.8211,  0.4085],\n",
            "        [-0.2684,  0.2914, -0.5193,  ..., -1.0614, -0.8025,  0.5659],\n",
            "        [-0.2693,  0.2894, -0.5144,  ..., -1.3457, -0.9549,  0.5054]])\n",
            "Old tensor([[-0.0274,  0.0298, -0.0530,  ..., -0.0864, -0.0476,  0.1064],\n",
            "        [-0.0275,  0.0294, -0.0512,  ..., -0.0575, -0.0539,  0.0231],\n",
            "        [-0.0271,  0.0291, -0.0514,  ..., -0.1100, -0.0795,  0.0477],\n",
            "        ...,\n",
            "        [-0.0272,  0.0297, -0.0532,  ..., -0.1018, -0.0599,  0.0978],\n",
            "        [-0.0269,  0.0290, -0.0513,  ..., -0.1300, -0.0966,  0.0552],\n",
            "        [-0.0271,  0.0299, -0.0532,  ..., -0.0988, -0.0428,  0.1166]])\n",
            "New tensor([[-0.2738,  0.2983, -0.5297,  ..., -0.8644, -0.4764,  1.0642],\n",
            "        [-0.2751,  0.2936, -0.5115,  ..., -0.5747, -0.5394,  0.2315],\n",
            "        [-0.2707,  0.2907, -0.5142,  ..., -1.1004, -0.7951,  0.4767],\n",
            "        ...,\n",
            "        [-0.2720,  0.2972, -0.5319,  ..., -1.0177, -0.5986,  0.9781],\n",
            "        [-0.2694,  0.2898, -0.5132,  ..., -1.3003, -0.9663,  0.5517],\n",
            "        [-0.2711,  0.2991, -0.5323,  ..., -0.9881, -0.4276,  1.1659]])\n",
            "Old tensor([[-0.0270,  0.0290, -0.0513,  ..., -0.1222, -0.0868,  0.0497],\n",
            "        [-0.0271,  0.0292, -0.0514,  ..., -0.0813, -0.0774,  0.0276],\n",
            "        [-0.0272,  0.0292, -0.0515,  ..., -0.0855, -0.0690,  0.0361],\n",
            "        ...,\n",
            "        [-0.0272,  0.0292, -0.0514,  ..., -0.0975, -0.0766,  0.0421],\n",
            "        [-0.0273,  0.0298, -0.0530,  ..., -0.0845, -0.0509,  0.0918],\n",
            "        [-0.0268,  0.0290, -0.0517,  ..., -0.1059, -0.0861,  0.0411]])\n",
            "New tensor([[-0.2702,  0.2903, -0.5131,  ..., -1.2216, -0.8684,  0.4970],\n",
            "        [-0.2713,  0.2920, -0.5139,  ..., -0.8130, -0.7743,  0.2765],\n",
            "        [-0.2721,  0.2917, -0.5146,  ..., -0.8551, -0.6899,  0.3608],\n",
            "        ...,\n",
            "        [-0.2717,  0.2917, -0.5135,  ..., -0.9746, -0.7657,  0.4215],\n",
            "        [-0.2733,  0.2981, -0.5298,  ..., -0.8451, -0.5094,  0.9183],\n",
            "        [-0.2684,  0.2902, -0.5169,  ..., -1.0594, -0.8614,  0.4107]])\n",
            "Old tensor([[-0.0274,  0.0293, -0.0511,  ..., -0.0677, -0.0615,  0.0276],\n",
            "        [-0.0272,  0.0292, -0.0514,  ..., -0.0858, -0.0706,  0.0404],\n",
            "        [-0.0272,  0.0298, -0.0529,  ..., -0.0890, -0.0418,  0.1012],\n",
            "        ...,\n",
            "        [-0.0271,  0.0292, -0.0513,  ..., -0.1002, -0.0826,  0.0481],\n",
            "        [-0.0273,  0.0297, -0.0529,  ..., -0.0821, -0.0490,  0.0985],\n",
            "        [-0.0273,  0.0292, -0.0514,  ..., -0.0825, -0.0665,  0.0409]])\n",
            "New tensor([[-0.2744,  0.2933, -0.5110,  ..., -0.6766, -0.6147,  0.2757],\n",
            "        [-0.2717,  0.2921, -0.5137,  ..., -0.8581, -0.7063,  0.4044],\n",
            "        [-0.2717,  0.2982, -0.5294,  ..., -0.8905, -0.4181,  1.0117],\n",
            "        ...,\n",
            "        [-0.2708,  0.2918, -0.5126,  ..., -1.0016, -0.8261,  0.4810],\n",
            "        [-0.2726,  0.2975, -0.5285,  ..., -0.8206, -0.4898,  0.9849],\n",
            "        [-0.2730,  0.2921, -0.5141,  ..., -0.8253, -0.6650,  0.4087]])\n",
            "Old tensor([[-0.0271,  0.0300, -0.0538,  ..., -0.1023, -0.0393,  0.1368],\n",
            "        [-0.0273,  0.0293, -0.0512,  ..., -0.0817, -0.0706,  0.0379],\n",
            "        [-0.0272,  0.0292, -0.0513,  ..., -0.0842, -0.0767,  0.0298],\n",
            "        ...,\n",
            "        [-0.0269,  0.0290, -0.0516,  ..., -0.1074, -0.0889,  0.0388],\n",
            "        [-0.0270,  0.0292, -0.0518,  ..., -0.1033, -0.0805,  0.0504],\n",
            "        [-0.0278,  0.0293, -0.0508,  ..., -0.0661, -0.0581,  0.0252]])\n",
            "New tensor([[-0.2712,  0.3003, -0.5379,  ..., -1.0232, -0.3926,  1.3677],\n",
            "        [-0.2727,  0.2925, -0.5122,  ..., -0.8167, -0.7058,  0.3790],\n",
            "        [-0.2721,  0.2920, -0.5135,  ..., -0.8420, -0.7674,  0.2981],\n",
            "        ...,\n",
            "        [-0.2689,  0.2905, -0.5162,  ..., -1.0741, -0.8891,  0.3876],\n",
            "        [-0.2697,  0.2916, -0.5179,  ..., -1.0325, -0.8051,  0.5044],\n",
            "        [-0.2777,  0.2931, -0.5081,  ..., -0.6609, -0.5812,  0.2523]])\n",
            "Validation loss 0.0022738398984074593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "72vjD-UoYzLU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}